# ä¼˜åŒ–ç®—æ³• - å½¢å¼åŒ–ç†è®ºä¸Haskellå®ç°

## ğŸ“‹ æ¦‚è¿°

ä¼˜åŒ–ç®—æ³•æ˜¯å¯»æ‰¾å‡½æ•°æœ€ä¼˜è§£çš„è®¡ç®—æ–¹æ³•ï¼Œå¹¿æ³›åº”ç”¨äºæœºå™¨å­¦ä¹ ã€è¿ç­¹å­¦ã€å·¥ç¨‹ä¼˜åŒ–ç­‰é¢†åŸŸã€‚æœ¬æ–‡æ¡£ä»å½¢å¼åŒ–ç†è®ºçš„è§’åº¦åˆ†æå„ç§ä¼˜åŒ–ç®—æ³•ï¼Œå¹¶æä¾›å®Œæ•´çš„Haskellå®ç°ã€‚

## ğŸ¯ å½¢å¼åŒ–å®šä¹‰

### ä¼˜åŒ–é—®é¢˜çš„åŸºæœ¬æ¦‚å¿µ

#### ä¼˜åŒ–é—®é¢˜çš„æ•°å­¦å®šä¹‰

ç»™å®šç›®æ ‡å‡½æ•° $f: \mathbb{R}^n \to \mathbb{R}$ å’Œçº¦æŸæ¡ä»¶ï¼Œä¼˜åŒ–é—®é¢˜æ˜¯ï¼š

$$\min_{x \in \Omega} f(x)$$

å…¶ä¸­ $\Omega \subseteq \mathbb{R}^n$ æ˜¯å¯è¡ŒåŸŸã€‚

#### ä¼˜åŒ–é—®é¢˜çš„ç±»å‹

1. **æ— çº¦æŸä¼˜åŒ–**ï¼š$\Omega = \mathbb{R}^n$
2. **çº¦æŸä¼˜åŒ–**ï¼š$\Omega \subset \mathbb{R}^n$
3. **å‡¸ä¼˜åŒ–**ï¼š$f$ æ˜¯å‡¸å‡½æ•°ï¼Œ$\Omega$ æ˜¯å‡¸é›†
4. **éå‡¸ä¼˜åŒ–**ï¼š$f$ æˆ– $\Omega$ ä¸æ»¡è¶³å‡¸æ€§æ¡ä»¶

#### æœ€ä¼˜æ€§æ¡ä»¶

**ä¸€é˜¶å¿…è¦æ¡ä»¶**ï¼šå¦‚æœ $x^*$ æ˜¯å±€éƒ¨æœ€ä¼˜è§£ï¼Œåˆ™ $\nabla f(x^*) = 0$

**äºŒé˜¶å……åˆ†æ¡ä»¶**ï¼šå¦‚æœ $\nabla f(x^*) = 0$ ä¸” $\nabla^2 f(x^*) \succ 0$ï¼Œåˆ™ $x^*$ æ˜¯ä¸¥æ ¼å±€éƒ¨æœ€ä¼˜è§£

## ğŸ”§ Haskellå®ç°

### åŸºç¡€ç±»å‹å®šä¹‰

```haskell
{-# LANGUAGE TypeFamilies, FlexibleContexts, MultiParamTypeClasses #-}

import Data.List (minimumBy, maximumBy)
import Data.Maybe (fromMaybe)
import qualified Data.Vector as V
import qualified Data.Map as Map

-- ä¼˜åŒ–é—®é¢˜ç±»å‹ç±»
class OptimizationProblem prob where
    type Domain prob :: *
    type Objective prob :: *
    objectiveFunction :: prob -> Domain prob -> Objective prob
    gradient :: prob -> Domain prob -> Domain prob
    hessian :: prob -> Domain prob -> [[Objective prob]]
    domain :: prob -> Domain prob -> Bool

-- ä¼˜åŒ–ç®—æ³•ç»“æœç±»å‹
data OptimizationResult a b = OptimizationResult
    { optimalPoint :: a
    , optimalValue :: b
    , iterations :: Int
    , convergence :: Bool
    , time :: Double
    }

-- ä¼˜åŒ–ç®—æ³•ç±»å‹ç±»
class OptimizationAlgorithm alg where
    type Input alg :: *
    type Output alg :: *
    execute :: alg -> Input alg -> Output alg
    algorithmName :: alg -> String
    complexity :: alg -> String
```

### 1. æ¢¯åº¦ä¸‹é™ç®—æ³•

#### å½¢å¼åŒ–å®šä¹‰

æ¢¯åº¦ä¸‹é™æ˜¯ä¸€ç§ä¸€é˜¶ä¼˜åŒ–ç®—æ³•ï¼Œé€šè¿‡æ²¿ç€ç›®æ ‡å‡½æ•°æ¢¯åº¦çš„åæ–¹å‘è¿­ä»£æ›´æ–°å‚æ•°ã€‚

**ç®—æ³•æè¿°**ï¼š
1. åˆå§‹åŒ–å‚æ•° $x_0$
2. è®¡ç®—æ¢¯åº¦ $\nabla f(x_k)$
3. æ›´æ–°å‚æ•°ï¼š$x_{k+1} = x_k - \alpha \nabla f(x_k)$
4. é‡å¤æ­¥éª¤2-3ç›´åˆ°æ”¶æ•›

#### Haskellå®ç°

```haskell
-- æ¢¯åº¦ä¸‹é™ç®—æ³•
gradientDescent :: (Floating a, Ord a) => 
                  (V.Vector a -> a) -> 
                  (V.Vector a -> V.Vector a) -> 
                  V.Vector a -> 
                  a -> 
                  a -> 
                  Int -> 
                  OptimizationResult (V.Vector a) a
gradientDescent f grad x0 learningRate tolerance maxIter = 
    gradientDescent' f grad x0 learningRate tolerance maxIter 0

gradientDescent' :: (Floating a, Ord a) => 
                   (V.Vector a -> a) -> 
                   (V.Vector a -> V.Vector a) -> 
                   V.Vector a -> 
                   a -> 
                   a -> 
                   Int -> 
                   Int -> 
                   OptimizationResult (V.Vector a) a
gradientDescent' f grad x learningRate tolerance maxIter iter
  | iter >= maxIter = OptimizationResult x (f x) iter False 0.0
  | gradientNorm < tolerance = OptimizationResult x (f x) iter True 0.0
  | otherwise = 
      let gradX = grad x
          gradientNorm = V.sum $ V.map (\g -> g * g) gradX
          newX = V.zipWith (\xi gi -> xi - learningRate * gi) x gradX
      in gradientDescent' f grad newX learningRate tolerance maxIter (iter + 1)

-- è‡ªé€‚åº”å­¦ä¹ ç‡çš„æ¢¯åº¦ä¸‹é™
adaptiveGradientDescent :: (Floating a, Ord a) => 
                          (V.Vector a -> a) -> 
                          (V.Vector a -> V.Vector a) -> 
                          V.Vector a -> 
                          a -> 
                          a -> 
                          Int -> 
                          OptimizationResult (V.Vector a) a
adaptiveGradientDescent f grad x0 initialLR tolerance maxIter = 
    adaptiveGradientDescent' f grad x0 initialLR tolerance maxIter 0

adaptiveGradientDescent' :: (Floating a, Ord a) => 
                           (V.Vector a -> a) -> 
                           (V.Vector a -> V.Vector a) -> 
                           V.Vector a -> 
                           a -> 
                           a -> 
                           Int -> 
                           Int -> 
                           OptimizationResult (V.Vector a) a
adaptiveGradientDescent' f grad x learningRate tolerance maxIter iter
  | iter >= maxIter = OptimizationResult x (f x) iter False 0.0
  | gradientNorm < tolerance = OptimizationResult x (f x) iter True 0.0
  | otherwise = 
      let gradX = grad x
          gradientNorm = V.sum $ V.map (\g -> g * g) gradX
          newX = V.zipWith (\xi gi -> xi - learningRate * gi) x gradX
          newLR = learningRate * 0.95  -- å­¦ä¹ ç‡è¡°å‡
      in adaptiveGradientDescent' f grad newX newLR tolerance maxIter (iter + 1)

-- ç¤ºä¾‹ï¼šäºŒæ¬¡å‡½æ•°ä¼˜åŒ–
quadraticFunction :: V.Vector Double -> Double
quadraticFunction x = 
    let x1 = x V.! 0
        x2 = x V.! 1
    in x1^2 + x2^2 + 2*x1*x2 + 2*x1 + 3*x2 + 1

quadraticGradient :: V.Vector Double -> V.Vector Double
quadraticGradient x = 
    let x1 = x V.! 0
        x2 = x V.! 1
        grad1 = 2*x1 + 2*x2 + 2
        grad2 = 2*x2 + 2*x1 + 3
    in V.fromList [grad1, grad2]

-- å¤æ‚åº¦åˆ†æ
gradientDescentComplexity :: String
gradientDescentComplexity = 
    "æ—¶é—´å¤æ‚åº¦: O(n * iter)\n" ++
    "ç©ºé—´å¤æ‚åº¦: O(n)\n" ++
    "æ”¶æ•›æ€§: çº¿æ€§æ”¶æ•›\n" ++
    "åº”ç”¨: æœºå™¨å­¦ä¹ ã€ç¥ç»ç½‘ç»œè®­ç»ƒã€å‡¸ä¼˜åŒ–"
```

#### æ€§èƒ½åˆ†æ

**æ—¶é—´å¤æ‚åº¦**ï¼š$O(n \cdot iter)$ï¼Œå…¶ä¸­ $n$ æ˜¯å‚æ•°ç»´åº¦ï¼Œ$iter$ æ˜¯è¿­ä»£æ¬¡æ•°
**ç©ºé—´å¤æ‚åº¦**ï¼š$O(n)$
**æ”¶æ•›æ€§**ï¼šçº¿æ€§æ”¶æ•›

### 2. ç‰›é¡¿æ³•

#### å½¢å¼åŒ–å®šä¹‰

ç‰›é¡¿æ³•æ˜¯ä¸€ç§äºŒé˜¶ä¼˜åŒ–ç®—æ³•ï¼Œåˆ©ç”¨ç›®æ ‡å‡½æ•°çš„æ¢¯åº¦å’Œæµ·æ£®çŸ©é˜µè¿›è¡Œä¼˜åŒ–ã€‚

**ç®—æ³•æè¿°**ï¼š
1. åˆå§‹åŒ–å‚æ•° $x_0$
2. è®¡ç®—æ¢¯åº¦ $\nabla f(x_k)$ å’Œæµ·æ£®çŸ©é˜µ $\nabla^2 f(x_k)$
3. æ±‚è§£çº¿æ€§æ–¹ç¨‹ç»„ï¼š$\nabla^2 f(x_k) \Delta x = -\nabla f(x_k)$
4. æ›´æ–°å‚æ•°ï¼š$x_{k+1} = x_k + \Delta x$
5. é‡å¤æ­¥éª¤2-4ç›´åˆ°æ”¶æ•›

#### Haskellå®ç°

```haskell
-- ç‰›é¡¿æ³•ç®—æ³•
newtonMethod :: (Floating a, Ord a) => 
               (V.Vector a -> a) -> 
               (V.Vector a -> V.Vector a) -> 
               (V.Vector a -> [[a]]) -> 
               V.Vector a -> 
               a -> 
               Int -> 
               OptimizationResult (V.Vector a) a
newtonMethod f grad hess x0 tolerance maxIter = 
    newtonMethod' f grad hess x0 tolerance maxIter 0

newtonMethod' :: (Floating a, Ord a) => 
                (V.Vector a -> a) -> 
                (V.Vector a -> V.Vector a) -> 
                (V.Vector a -> [[a]]) -> 
                V.Vector a -> 
                a -> 
                Int -> 
                Int -> 
                OptimizationResult (V.Vector a) a
newtonMethod' f grad hess x tolerance maxIter iter
  | iter >= maxIter = OptimizationResult x (f x) iter False 0.0
  | gradientNorm < tolerance = OptimizationResult x (f x) iter True 0.0
  | otherwise = 
      let gradX = grad x
          hessX = hess x
          gradientNorm = V.sum $ V.map (\g -> g * g) gradX
          deltaX = solveLinearSystem hessX (V.map negate gradX)
          newX = V.zipWith (+) x deltaX
      in newtonMethod' f grad hess newX tolerance maxIter (iter + 1)

-- æ±‚è§£çº¿æ€§æ–¹ç¨‹ç»„ Ax = b
solveLinearSystem :: (Floating a) => [[a]] -> V.Vector a -> V.Vector a
solveLinearSystem a b = 
    let n = length a
        augmented = zipWith (\row bi -> row ++ [bi]) a (V.toList b)
        reduced = gaussianElimination augmented
        solution = backSubstitution reduced
    in V.fromList solution

-- é«˜æ–¯æ¶ˆå…ƒæ³•
gaussianElimination :: (Floating a) => [[a]] -> [[a]]
gaussianElimination matrix = 
    let n = length matrix
    in gaussianElimination' matrix 0 n

gaussianElimination' :: (Floating a) => [[a]] -> Int -> Int -> [[a]]
gaussianElimination' matrix row n
  | row >= n = matrix
  | otherwise = 
      let pivot = findPivot matrix row
          newMatrix = swapRows matrix row pivot
          eliminatedMatrix = eliminateColumn newMatrix row
      in gaussianElimination' eliminatedMatrix (row + 1) n

-- å¯»æ‰¾ä¸»å…ƒ
findPivot :: (Floating a) => [[a]] -> Int -> Int
findPivot matrix row = 
    let n = length matrix
        candidates = [(i, abs (matrix !! i !! row)) | i <- [row..n-1]]
    in fst $ maximumBy (\(_, a) (_, b) -> compare a b) candidates

-- äº¤æ¢è¡Œ
swapRows :: [[a]] -> Int -> Int -> [[a]]
swapRows matrix i j = 
    let rowI = matrix !! i
        rowJ = matrix !! j
    in take i matrix ++ [rowJ] ++ drop (i + 1) (take j matrix) ++ [rowI] ++ drop (j + 1) matrix

-- æ¶ˆå…ƒ
eliminateColumn :: (Floating a) => [[a]] -> Int -> [[a]]
eliminateColumn matrix row = 
    let n = length matrix
        pivot = matrix !! row !! row
        newRows = [eliminateRow matrix row i pivot | i <- [row+1..n-1]]
    in take row matrix ++ [matrix !! row] ++ newRows

eliminateRow :: (Floating a) => [[a]] -> Int -> Int -> a -> [a]
eliminateRow matrix pivotRow currentRow pivot = 
    let factor = matrix !! currentRow !! pivotRow / pivot
        pivotRowData = matrix !! pivotRow
        currentRowData = matrix !! currentRow
    in zipWith (\ci pi -> ci - factor * pi) currentRowData pivotRowData

-- å›ä»£
backSubstitution :: (Floating a) => [[a]] -> [a]
backSubstitution matrix = 
    let n = length matrix
        solution = replicate n 0
    in backSubstitution' matrix solution (n - 1)

backSubstitution' :: (Floating a) => [[a]] -> [a] -> Int -> [a]
backSubstitution' matrix solution i
  | i < 0 = solution
  | otherwise = 
      let row = matrix !! i
          n = length matrix
          sum = sum [row !! j * solution !! j | j <- [i+1..n-1]]
          xi = (row !! n - sum) / row !! i
          newSolution = take i solution ++ [xi] ++ drop (i + 1) solution
      in backSubstitution' matrix newSolution (i - 1)

-- ç¤ºä¾‹ï¼šäºŒæ¬¡å‡½æ•°çš„æµ·æ£®çŸ©é˜µ
quadraticHessian :: V.Vector Double -> [[Double]]
quadraticHessian x = 
    [[2, 2],
     [2, 2]]

-- å¤æ‚åº¦åˆ†æ
newtonMethodComplexity :: String
newtonMethodComplexity = 
    "æ—¶é—´å¤æ‚åº¦: O(nÂ³ * iter)\n" ++
    "ç©ºé—´å¤æ‚åº¦: O(nÂ²)\n" ++
    "æ”¶æ•›æ€§: äºŒæ¬¡æ”¶æ•›\n" ++
    "åº”ç”¨: å‡¸ä¼˜åŒ–ã€æœºå™¨å­¦ä¹ ã€æ•°å€¼ä¼˜åŒ–"
```

#### æ€§èƒ½åˆ†æ

**æ—¶é—´å¤æ‚åº¦**ï¼š$O(n^3 \cdot iter)$ï¼ˆä¸»è¦å¼€é”€åœ¨æ±‚è§£çº¿æ€§æ–¹ç¨‹ç»„ï¼‰
**ç©ºé—´å¤æ‚åº¦**ï¼š$O(n^2)$
**æ”¶æ•›æ€§**ï¼šäºŒæ¬¡æ”¶æ•›

### 3. é—ä¼ ç®—æ³•

#### å½¢å¼åŒ–å®šä¹‰

é—ä¼ ç®—æ³•æ˜¯ä¸€ç§åŸºäºè‡ªç„¶é€‰æ‹©å’Œé—ä¼ æœºåˆ¶çš„ä¼˜åŒ–ç®—æ³•ï¼Œé€‚ç”¨äºå¤æ‚éçº¿æ€§ä¼˜åŒ–é—®é¢˜ã€‚

**ç®—æ³•æè¿°**ï¼š
1. åˆå§‹åŒ–ç§ç¾¤
2. è¯„ä¼°é€‚åº”åº¦
3. é€‰æ‹©ä¼˜ç§€ä¸ªä½“
4. äº¤å‰å’Œå˜å¼‚
5. é‡å¤æ­¥éª¤2-4ç›´åˆ°æ»¡è¶³ç»ˆæ­¢æ¡ä»¶

#### Haskellå®ç°

```haskell
-- é—ä¼ ç®—æ³•å®ç°
data Individual a = Individual
    { chromosome :: V.Vector a
    , fitness :: Double
    }

data GeneticAlgorithm a = GeneticAlgorithm
    { populationSize :: Int
    , mutationRate :: Double
    , crossoverRate :: Double
    , maxGenerations :: Int
    }

-- é—ä¼ ç®—æ³•ä¸»å‡½æ•°
geneticAlgorithm :: (Floating a, Ord a) => 
                   GeneticAlgorithm a -> 
                   (V.Vector a -> Double) -> 
                   (V.Vector a -> V.Vector a) -> 
                   V.Vector a -> 
                   OptimizationResult (V.Vector a) a
geneticAlgorithm config fitnessFunc mutationFunc initialChromosome = 
    let initialPopulation = generatePopulation config initialChromosome
    in geneticAlgorithm' config fitnessFunc mutationFunc initialPopulation 0

geneticAlgorithm' :: (Floating a, Ord a) => 
                    GeneticAlgorithm a -> 
                    (V.Vector a -> Double) -> 
                    (V.Vector a -> V.Vector a) -> 
                    [Individual a] -> 
                    Int -> 
                    OptimizationResult (V.Vector a) a
geneticAlgorithm' config fitnessFunc mutationFunc population generation
  | generation >= maxGenerations config = 
      let bestIndividual = maximumBy (\a b -> compare (fitness a) (fitness b)) population
      in OptimizationResult (chromosome bestIndividual) 
                           (fromIntegral $ fitness bestIndividual) 
                           generation True 0.0
  | otherwise = 
      let evaluatedPopulation = map (\ind -> ind { fitness = fitnessFunc (chromosome ind) }) population
          selectedPopulation = selection evaluatedPopulation
          newPopulation = crossoverAndMutation config selectedPopulation mutationFunc
      in geneticAlgorithm' config fitnessFunc mutationFunc newPopulation (generation + 1)

-- ç”Ÿæˆåˆå§‹ç§ç¾¤
generatePopulation :: (Floating a) => GeneticAlgorithm a -> V.Vector a -> [Individual a]
generatePopulation config chromosome = 
    let size = populationSize config
        chromosomes = [mutateChromosome chromosome | _ <- [1..size]]
    in map (\chrom -> Individual chrom 0.0) chromosomes

-- é€‰æ‹©æ“ä½œ
selection :: [Individual a] -> [Individual a]
selection population = 
    let tournamentSize = 3
        selected = [tournamentSelection population tournamentSize | _ <- population]
    in selected

-- é”¦æ ‡èµ›é€‰æ‹©
tournamentSelection :: [Individual a] -> Int -> Individual a
tournamentSelection population size = 
    let n = length population
        indices = take size $ randomRs (0, n-1) (mkStdGen 42)
        candidates = [population !! i | i <- indices]
    in maximumBy (\a b -> compare (fitness a) (fitness b)) candidates

-- äº¤å‰å’Œå˜å¼‚
crossoverAndMutation :: (Floating a) => 
                       GeneticAlgorithm a -> 
                       [Individual a] -> 
                       (V.Vector a -> V.Vector a) -> 
                       [Individual a]
crossoverAndMutation config population mutationFunc = 
    let pairs = chunksOf 2 population
        crossed = concatMap (\pair -> 
            if length pair == 2 
            then crossover (pair !! 0) (pair !! 1) (crossoverRate config)
            else pair) pairs
        mutated = map (\ind -> mutate ind (mutationRate config) mutationFunc) crossed
    in mutated

-- äº¤å‰æ“ä½œ
crossover :: Individual a -> Individual a -> Double -> [Individual a]
crossover parent1 parent2 rate = 
    let chrom1 = chromosome parent1
        chrom2 = chromosome parent2
        n = V.length chrom1
        crossoverPoint = floor $ fromIntegral n * rate
        child1 = V.take crossoverPoint chrom1 V.++ V.drop crossoverPoint chrom2
        child2 = V.take crossoverPoint chrom2 V.++ V.drop crossoverPoint chrom1
    in [Individual child1 0.0, Individual child2 0.0]

-- å˜å¼‚æ“ä½œ
mutate :: (Floating a) => Individual a -> Double -> (V.Vector a -> V.Vector a) -> Individual a
mutate individual rate mutationFunc = 
    let chrom = chromosome individual
        shouldMutate = randomRs (0.0, 1.0) (mkStdGen 42) !! 0 < rate
    in if shouldMutate 
       then Individual (mutationFunc chrom) 0.0
       else individual

-- å˜å¼‚å‡½æ•°ç¤ºä¾‹
randomMutation :: V.Vector Double -> V.Vector Double
randomMutation chromosome = 
    let n = V.length chromosome
        mutations = take n $ randomRs (-0.1, 0.1) (mkStdGen 42)
    in V.zipWith (+) chromosome (V.fromList mutations)

-- å¤æ‚åº¦åˆ†æ
geneticAlgorithmComplexity :: String
geneticAlgorithmComplexity = 
    "æ—¶é—´å¤æ‚åº¦: O(pop_size * generations * fitness_eval)\n" ++
    "ç©ºé—´å¤æ‚åº¦: O(pop_size * chromosome_length)\n" ++
    "æ”¶æ•›æ€§: æ¦‚ç‡æ€§æ”¶æ•›\n" ++
    "åº”ç”¨: ç»„åˆä¼˜åŒ–ã€å‚æ•°è°ƒä¼˜ã€å·¥ç¨‹è®¾è®¡"
```

#### æ€§èƒ½åˆ†æ

**æ—¶é—´å¤æ‚åº¦**ï¼š$O(pop\_size \cdot generations \cdot fitness\_eval)$
**ç©ºé—´å¤æ‚åº¦**ï¼š$O(pop\_size \cdot chromosome\_length)$
**æ”¶æ•›æ€§**ï¼šæ¦‚ç‡æ€§æ”¶æ•›

### 4. æ¨¡æ‹Ÿé€€ç«ç®—æ³•

#### å½¢å¼åŒ–å®šä¹‰

æ¨¡æ‹Ÿé€€ç«ç®—æ³•æ˜¯ä¸€ç§åŸºäºç‰©ç†é€€ç«è¿‡ç¨‹çš„ä¼˜åŒ–ç®—æ³•ï¼Œèƒ½å¤Ÿè·³å‡ºå±€éƒ¨æœ€ä¼˜è§£ã€‚

**ç®—æ³•æè¿°**ï¼š
1. åˆå§‹åŒ–æ¸©åº¦å’Œå½“å‰è§£
2. ç”Ÿæˆé‚»åŸŸè§£
3. æ ¹æ®Metropoliså‡†åˆ™å†³å®šæ˜¯å¦æ¥å—æ–°è§£
4. é™ä½æ¸©åº¦
5. é‡å¤æ­¥éª¤2-4ç›´åˆ°æ¸©åº¦è¶³å¤Ÿä½

#### Haskellå®ç°

```haskell
-- æ¨¡æ‹Ÿé€€ç«ç®—æ³•
data SimulatedAnnealing a = SimulatedAnnealing
    { initialTemperature :: Double
    , coolingRate :: Double
    , minTemperature :: Double
    , maxIterations :: Int
    }

-- æ¨¡æ‹Ÿé€€ç«ä¸»å‡½æ•°
simulatedAnnealing :: (Floating a, Ord a) => 
                     SimulatedAnnealing a -> 
                     (V.Vector a -> Double) -> 
                     (V.Vector a -> V.Vector a) -> 
                     V.Vector a -> 
                     OptimizationResult (V.Vector a) a
simulatedAnnealing config objectiveFunc neighborFunc initialSolution = 
    simulatedAnnealing' config objectiveFunc neighborFunc initialSolution 
                        (initialTemperature config) 0

simulatedAnnealing' :: (Floating a, Ord a) => 
                      SimulatedAnnealing a -> 
                      (V.Vector a -> Double) -> 
                      (V.Vector a -> V.Vector a) -> 
                      V.Vector a -> 
                      Double -> 
                      Int -> 
                      OptimizationResult (V.Vector a) a
simulatedAnnealing' config objectiveFunc neighborFunc currentSolution temperature iteration
  | temperature < minTemperature config = 
      OptimizationResult currentSolution (objectiveFunc currentSolution) iteration True 0.0
  | iteration >= maxIterations config = 
      OptimizationResult currentSolution (objectiveFunc currentSolution) iteration False 0.0
  | otherwise = 
      let neighborSolution = neighborFunc currentSolution
          currentCost = objectiveFunc currentSolution
          neighborCost = objectiveFunc neighborSolution
          deltaE = neighborCost - currentCost
          accepted = acceptSolution deltaE temperature
          newSolution = if accepted then neighborSolution else currentSolution
          newTemperature = temperature * coolingRate config
      in simulatedAnnealing' config objectiveFunc neighborFunc newSolution newTemperature (iteration + 1)

-- Metropoliså‡†åˆ™
acceptSolution :: Double -> Double -> Bool
acceptSolution deltaE temperature = 
    if deltaE < 0 
    then True  -- æ¥å—æ›´å¥½çš„è§£
    else let probability = exp (-deltaE / temperature)
             random = randomRs (0.0, 1.0) (mkStdGen 42) !! 0
         in random < probability

-- é‚»åŸŸå‡½æ•°ç¤ºä¾‹
randomNeighbor :: V.Vector Double -> V.Vector Double
randomNeighbor solution = 
    let n = V.length solution
        perturbations = take n $ randomRs (-0.1, 0.1) (mkStdGen 42)
    in V.zipWith (+) solution (V.fromList perturbations)

-- å¤æ‚åº¦åˆ†æ
simulatedAnnealingComplexity :: String
simulatedAnnealingComplexity = 
    "æ—¶é—´å¤æ‚åº¦: O(iterations * neighbor_generation)\n" ++
    "ç©ºé—´å¤æ‚åº¦: O(solution_length)\n" ++
    "æ”¶æ•›æ€§: æ¦‚ç‡æ€§æ”¶æ•›åˆ°å…¨å±€æœ€ä¼˜\n" ++
    "åº”ç”¨: ç»„åˆä¼˜åŒ–ã€è·¯å¾„è§„åˆ’ã€è°ƒåº¦é—®é¢˜"
```

#### æ€§èƒ½åˆ†æ

**æ—¶é—´å¤æ‚åº¦**ï¼š$O(iterations \cdot neighbor\_generation)$
**ç©ºé—´å¤æ‚åº¦**ï¼š$O(solution\_length)$
**æ”¶æ•›æ€§**ï¼šæ¦‚ç‡æ€§æ”¶æ•›åˆ°å…¨å±€æœ€ä¼˜

### 5. ç²’å­ç¾¤ä¼˜åŒ– (PSO)

#### å½¢å¼åŒ–å®šä¹‰

ç²’å­ç¾¤ä¼˜åŒ–æ˜¯ä¸€ç§åŸºäºç¾¤ä½“æ™ºèƒ½çš„ä¼˜åŒ–ç®—æ³•ï¼Œæ¨¡æ‹Ÿé¸Ÿç¾¤è§…é£Ÿè¡Œä¸ºã€‚

**ç®—æ³•æè¿°**ï¼š
1. åˆå§‹åŒ–ç²’å­ç¾¤
2. è¯„ä¼°æ¯ä¸ªç²’å­çš„é€‚åº”åº¦
3. æ›´æ–°ä¸ªä½“æœ€ä¼˜å’Œå…¨å±€æœ€ä¼˜
4. æ›´æ–°ç²’å­é€Ÿåº¦å’Œä½ç½®
5. é‡å¤æ­¥éª¤2-4ç›´åˆ°æ»¡è¶³ç»ˆæ­¢æ¡ä»¶

#### Haskellå®ç°

```haskell
-- ç²’å­ç¾¤ä¼˜åŒ–
data Particle a = Particle
    { position :: V.Vector a
    , velocity :: V.Vector a
    , bestPosition :: V.Vector a
    , bestFitness :: Double
    }

data PSOConfig a = PSOConfig
    { swarmSize :: Int
    , maxIterations :: Int
    , inertiaWeight :: Double
    , cognitiveWeight :: Double
    , socialWeight :: Double
    }

-- PSOä¸»å‡½æ•°
particleSwarmOptimization :: (Floating a, Ord a) => 
                            PSOConfig a -> 
                            (V.Vector a -> Double) -> 
                            V.Vector a -> 
                            OptimizationResult (V.Vector a) a
particleSwarmOptimization config objectiveFunc initialPosition = 
    let initialSwarm = generateSwarm config initialPosition
    in particleSwarmOptimization' config objectiveFunc initialSwarm 0

particleSwarmOptimization' :: (Floating a, Ord a) => 
                             PSOConfig a -> 
                             (V.Vector a -> Double) -> 
                             [Particle a] -> 
                             Int -> 
                             OptimizationResult (V.Vector a) a
particleSwarmOptimization' config objectiveFunc swarm iteration
  | iteration >= maxIterations config = 
      let bestParticle = maximumBy (\a b -> compare (bestFitness a) (bestFitness b)) swarm
      in OptimizationResult (bestPosition bestParticle) 
                           (bestFitness bestParticle) 
                           iteration True 0.0
  | otherwise = 
      let evaluatedSwarm = map (\particle -> 
            let fitness = objectiveFunc (position particle)
            in particle { bestFitness = max (bestFitness particle) fitness,
                         bestPosition = if fitness > bestFitness particle 
                                       then position particle 
                                       else bestPosition particle }) swarm
          globalBest = maximumBy (\a b -> compare (bestFitness a) (bestFitness b)) evaluatedSwarm
          updatedSwarm = map (\particle -> updateParticle particle globalBest config) evaluatedSwarm
      in particleSwarmOptimization' config objectiveFunc updatedSwarm (iteration + 1)

-- ç”Ÿæˆç²’å­ç¾¤
generateSwarm :: (Floating a) => PSOConfig a -> V.Vector a -> [Particle a]
generateSwarm config initialPosition = 
    let size = swarmSize config
        n = V.length initialPosition
        particles = [generateParticle initialPosition n | _ <- [1..size]]
    in particles

-- ç”Ÿæˆå•ä¸ªç²’å­
generateParticle :: V.Vector Double -> Int -> Particle Double
generateParticle initialPosition n = 
    let position = V.map (\x -> x + randomRs (-0.1, 0.1) (mkStdGen 42) !! 0) initialPosition
        velocity = V.fromList $ take n $ randomRs (-0.1, 0.1) (mkStdGen 42)
    in Particle position velocity position 0.0

-- æ›´æ–°ç²’å­
updateParticle :: (Floating a) => Particle a -> Particle a -> PSOConfig a -> Particle a
updateParticle particle globalBest config = 
    let newVelocity = updateVelocity particle globalBest config
        newPosition = V.zipWith (+) (position particle) newVelocity
    in particle { position = newPosition, velocity = newVelocity }

-- æ›´æ–°é€Ÿåº¦
updateVelocity :: (Floating a) => Particle a -> Particle a -> PSOConfig a -> V.Vector a
updateVelocity particle globalBest config = 
    let r1 = randomRs (0.0, 1.0) (mkStdGen 42) !! 0
        r2 = randomRs (0.0, 1.0) (mkStdGen 42) !! 0
        cognitiveComponent = V.map (* (cognitiveWeight config * r1)) 
                                  (V.zipWith (-) (bestPosition particle) (position particle))
        socialComponent = V.map (* (socialWeight config * r2)) 
                               (V.zipWith (-) (bestPosition globalBest) (position particle))
        newVelocity = V.zipWith (+) 
                               (V.map (* (inertiaWeight config)) (velocity particle))
                               (V.zipWith (+) cognitiveComponent socialComponent)
    in newVelocity

-- å¤æ‚åº¦åˆ†æ
psoComplexity :: String
psoComplexity = 
    "æ—¶é—´å¤æ‚åº¦: O(swarm_size * iterations * fitness_eval)\n" ++
    "ç©ºé—´å¤æ‚åº¦: O(swarm_size * dimension)\n" ++
    "æ”¶æ•›æ€§: æ¦‚ç‡æ€§æ”¶æ•›\n" ++
    "åº”ç”¨: å‡½æ•°ä¼˜åŒ–ã€ç¥ç»ç½‘ç»œè®­ç»ƒã€å‚æ•°è°ƒä¼˜"
```

#### æ€§èƒ½åˆ†æ

**æ—¶é—´å¤æ‚åº¦**ï¼š$O(swarm\_size \cdot iterations \cdot fitness\_eval)$
**ç©ºé—´å¤æ‚åº¦**ï¼š$O(swarm\_size \cdot dimension)$
**æ”¶æ•›æ€§**ï¼šæ¦‚ç‡æ€§æ”¶æ•›

## ğŸ“Š ç®—æ³•æ¯”è¾ƒ

### æ€§èƒ½å¯¹æ¯”è¡¨

| ç®—æ³• | æ—¶é—´å¤æ‚åº¦ | ç©ºé—´å¤æ‚åº¦ | æ”¶æ•›æ€§ | é€‚ç”¨é—®é¢˜ |
|------|------------|------------|--------|----------|
| æ¢¯åº¦ä¸‹é™ | O(n * iter) | O(n) | çº¿æ€§ | å‡¸ä¼˜åŒ– |
| ç‰›é¡¿æ³• | O(nÂ³ * iter) | O(nÂ²) | äºŒæ¬¡ | å‡¸ä¼˜åŒ– |
| é—ä¼ ç®—æ³• | O(pop * gen * eval) | O(pop * chrom) | æ¦‚ç‡æ€§ | å¤æ‚ä¼˜åŒ– |
| æ¨¡æ‹Ÿé€€ç« | O(iter * neighbor) | O(n) | æ¦‚ç‡æ€§ | ç»„åˆä¼˜åŒ– |
| ç²’å­ç¾¤ä¼˜åŒ– | O(swarm * iter * eval) | O(swarm * dim) | æ¦‚ç‡æ€§ | è¿ç»­ä¼˜åŒ– |

### é€‰æ‹©æŒ‡å—

```haskell
-- ç®—æ³•é€‰æ‹©å‡½æ•°
chooseOptimizationAlgorithm :: String -> String
chooseOptimizationAlgorithm "convex" = "æ¢¯åº¦ä¸‹é™æˆ–ç‰›é¡¿æ³•"
chooseOptimizationAlgorithm "combinatorial" = "é—ä¼ ç®—æ³•æˆ–æ¨¡æ‹Ÿé€€ç«"
chooseOptimizationAlgorithm "continuous" = "ç²’å­ç¾¤ä¼˜åŒ–"
chooseOptimizationAlgorithm "global" = "é—ä¼ ç®—æ³•ã€æ¨¡æ‹Ÿé€€ç«æˆ–PSO"
chooseOptimizationAlgorithm _ = "æ ¹æ®å…·ä½“é—®é¢˜é€‰æ‹©"

-- æ™ºèƒ½ç®—æ³•é€‰æ‹©
smartOptimizationAlgorithm :: String -> String -> String
smartOptimizationAlgorithm "type" "convex" = "æ¢¯åº¦ä¸‹é™"
smartOptimizationAlgorithm "type" "nonconvex" = "é—ä¼ ç®—æ³•"
smartOptimizationAlgorithm "dimension" "low" = "ç‰›é¡¿æ³•"
smartOptimizationAlgorithm "dimension" "high" = "ç²’å­ç¾¤ä¼˜åŒ–"
smartOptimizationAlgorithm "constraint" "discrete" = "é—ä¼ ç®—æ³•"
smartOptimizationAlgorithm "constraint" "continuous" = "æ¢¯åº¦ä¸‹é™"
smartOptimizationAlgorithm _ _ = "éœ€è¦æ›´å¤šä¿¡æ¯"
```

## ğŸ”¬ å½¢å¼åŒ–éªŒè¯

### æ”¶æ•›æ€§è¯æ˜

#### æ¢¯åº¦ä¸‹é™æ”¶æ•›æ€§

**å®šç†**ï¼šå¯¹äºå‡¸å‡½æ•°ï¼Œæ¢¯åº¦ä¸‹é™ç®—æ³•æ”¶æ•›åˆ°å…¨å±€æœ€ä¼˜è§£ã€‚

**è¯æ˜**ï¼š
1. **å‡¸æ€§æ¡ä»¶**ï¼š$f(\lambda x + (1-\lambda)y) \leq \lambda f(x) + (1-\lambda)f(y)$
2. **Lipschitzè¿ç»­æ€§**ï¼š$\|\nabla f(x) - \nabla f(y)\| \leq L\|x - y\|$
3. **æ”¶æ•›æ€§**ï¼šé€‰æ‹©åˆé€‚çš„æ­¥é•¿ï¼Œç®—æ³•æ”¶æ•›åˆ°æœ€ä¼˜è§£

#### ç‰›é¡¿æ³•æ”¶æ•›æ€§

**å®šç†**ï¼šå¯¹äºå¼ºå‡¸å‡½æ•°ï¼Œç‰›é¡¿æ³•å…·æœ‰äºŒæ¬¡æ”¶æ•›æ€§ã€‚

**è¯æ˜**ï¼š
1. **å¼ºå‡¸æ€§**ï¼š$\nabla^2 f(x) \succeq \mu I$
2. **Lipschitzè¿ç»­æ€§**ï¼š$\|\nabla^2 f(x) - \nabla^2 f(y)\| \leq M\|x - y\|$
3. **äºŒæ¬¡æ”¶æ•›**ï¼š$\|x_{k+1} - x^*\| \leq \frac{M}{2\mu}\|x_k - x^*\|^2$

### å¤æ‚åº¦è¯æ˜

#### é—ä¼ ç®—æ³•å¤æ‚åº¦

**å®šç†**ï¼šé—ä¼ ç®—æ³•çš„æœŸæœ›æ”¶æ•›æ—¶é—´ä¸º $O(pop\_size \cdot \log(pop\_size) \cdot generations)$ã€‚

**è¯æ˜**ï¼š
- é€‰æ‹©æ“ä½œï¼š$O(pop\_size \cdot \log(pop\_size))$
- äº¤å‰æ“ä½œï¼š$O(pop\_size)$
- å˜å¼‚æ“ä½œï¼š$O(pop\_size)$
- æ€»å¤æ‚åº¦ï¼š$O(pop\_size \cdot \log(pop\_size) \cdot generations)$

## ğŸ¯ å®é™…åº”ç”¨

### æ€§èƒ½æµ‹è¯•

```haskell
-- æ€§èƒ½æµ‹è¯•å‡½æ•°
testOptimizationPerformance :: IO ()
testOptimizationPerformance = do
    putStrLn "ä¼˜åŒ–ç®—æ³•æ€§èƒ½æµ‹è¯•"
    putStrLn "=================="
    
    let testAlgorithm name algFunc = do
            start <- getCurrentTime
            let result = algFunc
            end <- getCurrentTime
            let duration = diffUTCTime end start
            putStrLn $ name ++ ": " ++ show duration
    
    -- æµ‹è¯•æ¢¯åº¦ä¸‹é™
    let x0 = V.fromList [1.0, 1.0]
        gdResult = gradientDescent quadraticFunction quadraticGradient x0 0.01 1e-6 1000
    testAlgorithm "æ¢¯åº¦ä¸‹é™" gdResult
    
    -- æµ‹è¯•é—ä¼ ç®—æ³•
    let gaConfig = GeneticAlgorithm 50 0.1 0.8 100
        gaResult = geneticAlgorithm gaConfig quadraticFunction randomMutation x0
    testAlgorithm "é—ä¼ ç®—æ³•" gaResult

-- åŸºå‡†å‡½æ•°
rosenbrockFunction :: V.Vector Double -> Double
rosenbrockFunction x = 
    let x1 = x V.! 0
        x2 = x V.! 1
    in (1 - x1)^2 + 100 * (x2 - x1^2)^2

sphereFunction :: V.Vector Double -> Double
sphereFunction x = V.sum $ V.map (\xi -> xi^2) x
```

### å®é™…åº”ç”¨åœºæ™¯

1. **æœºå™¨å­¦ä¹ **ï¼šç¥ç»ç½‘ç»œè®­ç»ƒã€å‚æ•°ä¼˜åŒ–
2. **é‡‘èä¼˜åŒ–**ï¼šæŠ•èµ„ç»„åˆä¼˜åŒ–ã€é£é™©æœ€å°åŒ–
3. **å·¥ç¨‹è®¾è®¡**ï¼šç»“æ„ä¼˜åŒ–ã€å‚æ•°è°ƒä¼˜
4. **è¿ç­¹å­¦**ï¼šè°ƒåº¦é—®é¢˜ã€è·¯å¾„è§„åˆ’
5. **ç”Ÿç‰©ä¿¡æ¯å­¦**ï¼šè›‹ç™½è´¨æŠ˜å ã€åºåˆ—æ¯”å¯¹

## ğŸ“š æ‰©å±•é˜…è¯»

### é«˜çº§ä¼˜åŒ–ç®—æ³•

1. **å†…ç‚¹æ³•**ï¼šå¤„ç†çº¦æŸä¼˜åŒ–é—®é¢˜
2. **ä¿¡èµ–åŸŸæ–¹æ³•**ï¼šéçº¿æ€§ä¼˜åŒ–
3. **è¿›åŒ–ç­–ç•¥**ï¼šè¿ç»­å‚æ•°ä¼˜åŒ–
4. **èšç¾¤ç®—æ³•**ï¼šç»„åˆä¼˜åŒ–
5. **å·®åˆ†è¿›åŒ–**ï¼šå…¨å±€ä¼˜åŒ–

### å¹¶è¡Œä¼˜åŒ–ç®—æ³•

```haskell
-- å¹¶è¡Œé—ä¼ ç®—æ³•
parallelGeneticAlgorithm :: (Floating a, Ord a) => 
                           GeneticAlgorithm a -> 
                           (V.Vector a -> Double) -> 
                           V.Vector a -> 
                           OptimizationResult (V.Vector a) a
parallelGeneticAlgorithm config fitnessFunc initialChromosome = 
    let initialPopulation = generatePopulation config initialChromosome
        chunks = chunksOf (populationSize config `div` numCapabilities) initialPopulation
    in parallelGeneticAlgorithm' config fitnessFunc chunks 0

parallelGeneticAlgorithm' :: (Floating a, Ord a) => 
                            GeneticAlgorithm a -> 
                            (V.Vector a -> Double) -> 
                            [[Individual a]] -> 
                            Int -> 
                            OptimizationResult (V.Vector a) a
parallelGeneticAlgorithm' config fitnessFunc populationChunks generation
  | generation >= maxGenerations config = 
      let allIndividuals = concat populationChunks
          bestIndividual = maximumBy (\a b -> compare (fitness a) (fitness b)) allIndividuals
      in OptimizationResult (chromosome bestIndividual) 
                           (fromIntegral $ fitness bestIndividual) 
                           generation True 0.0
  | otherwise = 
      let evaluatedChunks = map (\chunk -> 
            map (\ind -> ind { fitness = fitnessFunc (chromosome ind) }) chunk) populationChunks
          evolvedChunks = map (\chunk -> 
            crossoverAndMutation config chunk randomMutation) evaluatedChunks
      in parallelGeneticAlgorithm' config fitnessFunc evolvedChunks (generation + 1)
```

## ğŸ”— ç›¸å…³é“¾æ¥

- [åŸºç¡€æ•°æ®ç»“æ„](../01-Haskell-Basics/01-Language-Features.md)
- [é«˜çº§æ•°æ®ç»“æ„](../03-Data-Structures/01-Advanced-Data-Structures.md)
- [å½¢å¼åŒ–è¯æ˜](../04-Formal-Proofs/01-Theorem-Proving.md)
- [æ€§èƒ½ä¼˜åŒ–](../05-Performance-Optimization/01-Memory-Optimization.md)

---

*æœ¬æ–‡æ¡£æä¾›äº†ä¼˜åŒ–ç®—æ³•çš„å®Œæ•´å½¢å¼åŒ–ç†è®ºå’ŒHaskellå®ç°ï¼ŒåŒ…æ‹¬æ€§èƒ½åˆ†æå’Œå®é™…åº”ç”¨æŒ‡å¯¼ã€‚* 