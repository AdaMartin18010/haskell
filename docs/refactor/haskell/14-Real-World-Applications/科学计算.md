# 科学计算 - Haskell数值计算与科学应用

## 概述

Haskell在科学计算领域具有独特的优势，通过其强大的类型系统和函数式编程特性，可以构建安全、高效的科学计算应用。

## 数学基础

### 数值分析基础

科学计算基于以下数学理论：

- **数值线性代数**：矩阵运算、特征值分解、奇异值分解
- **数值积分**：数值求积、微分方程求解
- **优化理论**：线性规划、非线性优化、全局优化
- **统计计算**：概率分布、假设检验、回归分析

### 浮点数理论

IEEE 754浮点数标准：

$$x = (-1)^s \times 2^{e-b} \times (1.f)$$

其中：

- $s$ 是符号位
- $e$ 是指数位
- $f$ 是尾数位
- $b$ 是偏置

## Haskell科学计算库

### 基本数值类型

```haskell
-- 基本数值类型
import Data.Complex
import Data.Ratio

-- 复数类型
type ComplexDouble = Complex Double

-- 有理数类型
type Rational = Ratio Integer

-- 高精度数值
import Data.Number.Fixed

-- 固定精度类型
type Fixed = Fixed E12  -- 12位小数精度
```

### 向量和矩阵

```haskell
-- 使用hmatrix库
import Numeric.LinearAlgebra

-- 向量类型
type Vector = Vector Double
type VectorC = Vector (Complex Double)

-- 矩阵类型
type Matrix = Matrix Double
type MatrixC = Matrix (Complex Double)

-- 向量操作
v1 :: Vector
v1 = vector [1, 2, 3, 4, 5]

v2 :: Vector
v2 = vector [2, 3, 4, 5, 6]

-- 向量加法
vSum :: Vector
vSum = v1 + v2

-- 向量点积
dotProduct :: Double
dotProduct = v1 <.> v2

-- 向量范数
norm :: Double
norm = norm_2 v1

-- 矩阵操作
m1 :: Matrix
m1 = (3><3) [1, 2, 3,
             4, 5, 6,
             7, 8, 9]

-- 矩阵乘法
m2 :: Matrix
m2 = m1 <> m1

-- 矩阵转置
mTranspose :: Matrix
mTranspose = tr m1

-- 矩阵求逆
mInverse :: Matrix
mInverse = inv m1
```

### 线性代数计算

```haskell
-- 特征值分解
eigenDecomposition :: Matrix -> (Vector, Matrix)
eigenDecomposition m = (eigenvalues, eigenvectors)
  where
    (eigenvalues, eigenvectors) = eig m

-- 奇异值分解
svdDecomposition :: Matrix -> (Matrix, Vector, Matrix)
svdDecomposition m = (u, s, v)
  where
    (u, s, v) = svd m

-- LU分解
luDecomposition :: Matrix -> (Matrix, Matrix)
luDecomposition m = (l, u)
  where
    (l, u, _) = lu m

-- Cholesky分解
choleskyDecomposition :: Matrix -> Matrix
choleskyDecomposition m = chol m

-- QR分解
qrDecomposition :: Matrix -> (Matrix, Matrix)
qrDecomposition m = (q, r)
  where
    (q, r) = qr m
```

## 数值积分

### 基本积分方法

```haskell
-- 矩形法积分
rectangleIntegral :: (Double -> Double) -> Double -> Double -> Int -> Double
rectangleIntegral f a b n = h * sum [f (a + i * h) | i <- [0..n-1]]
  where
    h = (b - a) / fromIntegral n

-- 梯形法积分
trapezoidIntegral :: (Double -> Double) -> Double -> Double -> Int -> Double
trapezoidIntegral f a b n = h * (f a / 2 + sum [f (a + i * h) | i <- [1..n-1]] + f b / 2)
  where
    h = (b - a) / fromIntegral n

-- 辛普森法积分
simpsonIntegral :: (Double -> Double) -> Double -> Double -> Int -> Double
simpsonIntegral f a b n = h / 3 * (f a + 4 * sum1 + 2 * sum2 + f b)
  where
    h = (b - a) / fromIntegral n
    sum1 = sum [f (a + (2*i-1) * h) | i <- [1..n `div` 2]]
    sum2 = sum [f (a + 2*i * h) | i <- [1..(n-2) `div` 2]]

-- 自适应积分
adaptiveIntegral :: (Double -> Double) -> Double -> Double -> Double -> Double
adaptiveIntegral f a b tol = adaptiveStep f a b tol
  where
    adaptiveStep f a b tol
        | abs (s1 - s2) < tol = s2
        | otherwise = adaptiveStep f a mid tol + adaptiveStep f mid b tol
      where
        mid = (a + b) / 2
        s1 = simpsonIntegral f a b 2
        s2 = simpsonIntegral f a b 4
```

### 高斯求积

```haskell
-- 高斯-勒让德求积
gaussLegendre :: (Double -> Double) -> Double -> Double -> Int -> Double
gaussLegendre f a b n = (b - a) / 2 * sum [wi * f xi | (xi, wi) <- zip xis weights]
  where
    (xis, weights) = gaussLegendrePoints n
    xis' = map (\x -> (b - a) / 2 * x + (a + b) / 2) xis

-- 高斯点权重（预计算）
gaussLegendrePoints :: Int -> ([Double], [Double])
gaussLegendrePoints 2 = ([-0.5773502691896257, 0.5773502691896257], [1.0, 1.0])
gaussLegendrePoints 3 = ([-0.7745966692414834, 0.0, 0.7745966692414834], 
                         [0.5555555555555556, 0.8888888888888888, 0.5555555555555556])
gaussLegendrePoints 4 = ([-0.8611363115940526, -0.3399810435848563, 
                           0.3399810435848563, 0.8611363115940526],
                         [0.3478548451374538, 0.6521451548625461,
                          0.6521451548625461, 0.3478548451374538])
```

## 微分方程求解

### 常微分方程

```haskell
-- 欧拉方法
eulerMethod :: (Double -> Double -> Double) -> Double -> Double -> Double -> Int -> [Double]
eulerMethod f y0 t0 tf n = scanl step y0 times
  where
    h = (tf - t0) / fromIntegral n
    times = [t0 + i * h | i <- [0..n]]
    step y t = y + h * f t y

-- 龙格-库塔方法（四阶）
rungeKutta4 :: (Double -> Double -> Double) -> Double -> Double -> Double -> Int -> [Double]
rungeKutta4 f y0 t0 tf n = scanl step y0 times
  where
    h = (tf - t0) / fromIntegral n
    times = [t0 + i * h | i <- [0..n]]
    step y t = y + (h / 6) * (k1 + 2*k2 + 2*k3 + k4)
      where
        k1 = f t y
        k2 = f (t + h/2) (y + h*k1/2)
        k3 = f (t + h/2) (y + h*k2/2)
        k4 = f (t + h) (y + h*k3)

-- 自适应步长方法
adaptiveRK4 :: (Double -> Double -> Double) -> Double -> Double -> Double -> Double -> [Double]
adaptiveRK4 f y0 t0 tf tol = adaptiveStep f y0 t0 tf tol
  where
    adaptiveStep f y t tf tol
        | t >= tf = [y]
        | otherwise = y : adaptiveStep f y' (t + h) tf tol
      where
        h = min (tf - t) (optimalStep f y t tol)
        y' = rungeKuttaStep f y t h
    
    optimalStep f y t tol = sqrt (tol / abs (f t y))
    
    rungeKuttaStep f y t h = y + (h / 6) * (k1 + 2*k2 + 2*k3 + k4)
      where
        k1 = f t y
        k2 = f (t + h/2) (y + h*k1/2)
        k3 = f (t + h/2) (y + h*k2/2)
        k4 = f (t + h) (y + h*k3)
```

### 偏微分方程

```haskell
-- 有限差分方法
finiteDifference :: (Double -> Double -> Double) -> Double -> Double -> Int -> Matrix
finiteDifference f a b n = matrixFromList n n coefficients
  where
    h = (b - a) / fromIntegral (n + 1)
    coefficients = [finiteDiffCoeff i j | i <- [0..n-1], j <- [0..n-1]]
    
    finiteDiffCoeff i j
        | i == j = -2 / (h^2)
        | abs (i - j) == 1 = 1 / (h^2)
        | otherwise = 0

-- 热传导方程求解
heatEquation :: Double -> Double -> Int -> Int -> Matrix
heatEquation alpha dx dt nx nt = iterate step initialCondition !! nt
  where
    initialCondition = vector [sin (pi * i * dx) | i <- [0..nx]]
    step u = u + alpha * dt / (dx^2) * (shiftR u - 2 * u + shiftL u)
    
    shiftL v = subVector 1 (size v - 1) v
    shiftR v = subVector 0 (size v - 1) v
```

## 优化算法

### 无约束优化

```haskell
-- 梯度下降
gradientDescent :: (Vector -> Double) -> (Vector -> Vector) -> Vector -> Double -> Int -> [Vector]
gradientDescent f grad x0 learningRate maxIter = take maxIter $ iterate step x0
  where
    step x = x - scale learningRate (grad x)

-- 牛顿法
newtonMethod :: (Vector -> Double) -> (Vector -> Vector) -> (Vector -> Matrix) -> Vector -> Int -> [Vector]
newtonMethod f grad hessian x0 maxIter = take maxIter $ iterate step x0
  where
    step x = x - inv (hessian x) `mXv` grad x

-- 共轭梯度法
conjugateGradient :: Matrix -> Vector -> Vector -> Int -> [Vector]
conjugateGradient a b x0 maxIter = take maxIter $ iterate step (x0, r0, r0)
  where
    r0 = b - a `mXv` x0
    step (x, r, p) = (x', r', p')
      where
        alpha = (r <.> r) / (p <.> (a `mXv` p))
        x' = x + scale alpha p
        r' = r - scale alpha (a `mXv` p)
        beta = (r' <.> r') / (r <.> r)
        p' = r' + scale beta p
```

### 约束优化

```haskell
-- 拉格朗日乘数法
lagrangeMultipliers :: (Vector -> Double) -> [Vector -> Double] -> Vector -> Vector
lagrangeMultipliers f constraints x0 = solveLagrangeSystem f constraints x0

-- 内点法
interiorPoint :: (Vector -> Double) -> [Vector -> Double] -> Vector -> Double -> Int -> [Vector]
interiorPoint f constraints x0 mu maxIter = take maxIter $ iterate step x0
  where
    step x = newtonStep x mu
    
    newtonStep x mu = x + deltaX
      where
        (deltaX, _) = solveKKTSystem x mu

-- KKT系统求解
solveKKTSystem :: Vector -> Double -> (Vector, Vector)
solveKKTSystem x mu = (deltaX, lambda)
  where
    -- 构建KKT矩阵
    kktMatrix = buildKKTMatrix x mu
    kktRHS = buildKKTRHS x mu
    solution = linearSolve kktMatrix kktRHS
    deltaX = subVector 0 n solution
    lambda = subVector n m solution
    n = size x
    m = length constraints
```

## 统计计算

### 概率分布

```haskell
-- 正态分布
normalDistribution :: Double -> Double -> Double -> Double
normalDistribution mu sigma x = (1 / (sigma * sqrt (2 * pi))) * exp (-((x - mu)^2) / (2 * sigma^2))

-- 累积正态分布
cumulativeNormal :: Double -> Double -> Double -> Double
cumulativeNormal mu sigma x = 0.5 * (1 + erf ((x - mu) / (sigma * sqrt 2)))
  where
    erf z = 2 / sqrt pi * integrate 0 z (\t -> exp (-t^2))
    integrate a b f = simpsonIntegral f a b 1000

-- 随机数生成
import System.Random

-- 正态分布随机数
normalRandom :: Double -> Double -> IO Double
normalRandom mu sigma = do
    u1 <- randomRIO (0, 1)
    u2 <- randomRIO (0, 1)
    let z = sqrt (-2 * log u1) * cos (2 * pi * u2)
    return (mu + sigma * z)

-- 蒙特卡洛积分
monteCarloIntegral :: (Vector -> Double) -> Vector -> Vector -> Int -> IO Double
monteCarloIntegral f a b n = do
    samples <- replicateM n (randomVector a b)
    let values = map f samples
    return ((volume a b) * (sum values / fromIntegral n))
  where
    volume a b = product (zipWith (-) (toList b) (toList a))
    
    randomVector a b = do
        components <- zipWithM randomRIO (zip (toList a) (toList b))
        return (vector components)
```

### 假设检验

```haskell
-- t检验
tTest :: Vector -> Vector -> Double
tTest x y = (meanX - meanY) / sqrt (varX/nx + varY/ny)
  where
    meanX = mean x
    meanY = mean y
    varX = variance x
    varY = variance y
    nx = fromIntegral (size x)
    ny = fromIntegral (size y)

-- 卡方检验
chiSquareTest :: Vector -> Vector -> Double
chiSquareTest observed expected = sum [((o - e)^2) / e | (o, e) <- zip (toList observed) (toList expected)]

-- 线性回归
linearRegression :: Matrix -> Vector -> (Vector, Double)
linearRegression x y = (beta, rSquared)
  where
    beta = inv (tr x <> x) <> tr x <> y
    yPred = x <> beta
    ssRes = sum ((y - yPred)^2)
    ssTot = sum ((y - mean y)^2)
    rSquared = 1 - ssRes / ssTot
```

## 实际应用

### 金融计算

```haskell
-- 期权定价（Black-Scholes模型）
blackScholes :: Double -> Double -> Double -> Double -> Double -> Double -> Double
blackScholes s k t r sigma callPut = s * n d1 - k * exp (-r * t) * n d2
  where
    d1 = (log (s / k) + (r + sigma^2 / 2) * t) / (sigma * sqrt t)
    d2 = d1 - sigma * sqrt t
    n x = cumulativeNormal 0 1 x

-- 蒙特卡洛期权定价
monteCarloOption :: Double -> Double -> Double -> Double -> Double -> Int -> IO Double
monteCarloOption s k t r sigma n = do
    paths <- replicateM n (generatePath s t r sigma)
    let payoffs = map (\sT -> max 0 (sT - k)) paths
    return (exp (-r * t) * sum payoffs / fromIntegral n)
  where
    generatePath s0 t r sigma = do
        z <- normalRandom 0 1
        let sT = s0 * exp ((r - sigma^2/2) * t + sigma * sqrt t * z)
        return sT
```

### 信号处理

```haskell
-- 快速傅里叶变换
fft :: Vector -> Vector
fft v
    | size v == 1 = v
    | otherwise = combine (fft even) (fft odd)
  where
    n = size v
    even = subVector 0 (n `div` 2) v
    odd = subVector (n `div` 2) (n `div` 2) v
    
    combine evenFFT oddFFT = evenFFT + scale omega oddFFT
      where
        omega = exp (-2 * pi * i / fromIntegral n)
        i = 0 :+ 1

-- 数字滤波器
lowPassFilter :: Double -> Vector -> Vector
lowPassFilter cutoff signal = fft signal * filterResponse
  where
    filterResponse = vector [if abs freq < cutoff then 1 else 0 | freq <- frequencies]
    frequencies = vector [2 * pi * k / fromIntegral (size signal) | k <- [0..size signal - 1]]
```

## 性能优化

### 并行计算

```haskell
-- 并行矩阵乘法
parallelMatrixMultiply :: Matrix -> Matrix -> Matrix
parallelMatrixMultiply a b = matrix (rows a) (cols b) $ 
    concat [parallelRow i | i <- [0..rows a - 1]]
  where
    parallelRow i = concat [parallelElement i j | j <- [0..cols b - 1]]
    parallelElement i j = [sum [a `atIndex` (i, k) * b `atIndex` (k, j) | k <- [0..cols a - 1]]]

-- 并行积分
parallelIntegral :: (Double -> Double) -> Double -> Double -> Int -> Double
parallelIntegral f a b n = sum (map worker chunks)
  where
    chunkSize = n `div` numCapabilities
    chunks = [(a + i * chunkSize * h, a + (i + 1) * chunkSize * h) | i <- [0..numCapabilities - 1]]
    h = (b - a) / fromIntegral n
    
    worker (start, end) = simpsonIntegral f start end chunkSize
```

### 内存优化

```haskell
-- 流式处理大数据
streamProcess :: (a -> b) -> [a] -> [b]
streamProcess f = map f

-- 内存映射文件
memoryMappedFile :: FilePath -> IO (Vector Double)
memoryMappedFile path = do
    handle <- openBinaryFile path ReadMode
    size <- hFileSize handle
    let numDoubles = fromIntegral size `div` 8
    vector <- mallocVector numDoubles
    hGetBuf handle (castPtr vector) (fromIntegral size)
    hClose handle
    return vector
```

## 总结

Haskell在科学计算中的优势：

1. **类型安全**：编译时捕获数值错误
2. **函数式特性**：易于实现数学算法
3. **并行计算**：天然支持并行处理
4. **内存安全**：避免内存泄漏和越界访问
5. **可组合性**：函数可以轻松组合和重用

这些特性使Haskell成为科学计算的理想选择。

---

**相关链接**：

- [数值算法](../07-Algorithms/优化算法.md)
- [并行计算](../08-Concurrency/并行计算.md)
- [内存优化](../09-Performance/内存优化.md)
- [高级特性](../10-Advanced-Features/类型族.md)
