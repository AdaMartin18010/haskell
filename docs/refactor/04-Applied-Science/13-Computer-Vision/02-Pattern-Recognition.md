# è®¡ç®—æœºè§†è§‰æ¨¡å¼è¯†åˆ«ç†è®º (Pattern Recognition Theory)

## ğŸ“‹ æ–‡æ¡£ä¿¡æ¯

- **æ–‡æ¡£ç¼–å·**: 04-13-02
- **æ‰€å±å±‚çº§**: åº”ç”¨ç§‘å­¦å±‚ - è®¡ç®—æœºè§†è§‰
- **åˆ›å»ºæ—¶é—´**: 2024å¹´12æœˆ19æ—¥
- **æœ€åæ›´æ–°**: 2024å¹´12æœˆ19æ—¥
- **æ–‡æ¡£çŠ¶æ€**: å®Œæˆ

---

## ğŸ¯ æ¦‚è¿°

æ¨¡å¼è¯†åˆ«æ˜¯è®¡ç®—æœºè§†è§‰çš„æ ¸å¿ƒæŠ€æœ¯ï¼Œæ¶‰åŠä»å›¾åƒä¸­æå–ç‰¹å¾ã€å­¦ä¹ æ¨¡å¼å¹¶è¿›è¡Œåˆ†ç±»ã€‚æœ¬æ–‡æ¡£ç³»ç»Ÿæ€§åœ°ä»‹ç»ç‰¹å¾æå–ã€åˆ†ç±»å™¨è®¾è®¡ã€æ·±åº¦å­¦ä¹ ç­‰æ¨¡å¼è¯†åˆ«çš„ç†è®ºåŸºç¡€å’Œå®ç°æ–¹æ³•ã€‚

## ğŸ“š ç†è®ºåŸºç¡€

### 1. ç‰¹å¾æå–

#### 1.1 è¾¹ç¼˜æ£€æµ‹

Cannyè¾¹ç¼˜æ£€æµ‹çš„æ¢¯åº¦å¹…å€¼ï¼š

$$G = \sqrt{G_x^2 + G_y^2}$$

å…¶ä¸­ $G_x$ å’Œ $G_y$ åˆ†åˆ«æ˜¯xå’Œyæ–¹å‘çš„æ¢¯åº¦ã€‚

#### 1.2 SIFTç‰¹å¾

SIFTç‰¹å¾æè¿°å­çš„æ¢¯åº¦æ–¹å‘ç›´æ–¹å›¾ï¼š

$$h(k) = \sum_{i,j} w(i,j) \delta(\theta(i,j) - k)$$

å…¶ä¸­ $w(i,j)$ æ˜¯é«˜æ–¯æƒé‡ï¼Œ$\theta(i,j)$ æ˜¯æ¢¯åº¦æ–¹å‘ã€‚

#### 1.3 HOGç‰¹å¾

HOGç‰¹å¾çš„æ–¹å‘æ¢¯åº¦ç›´æ–¹å›¾ï¼š

$$HOG = [h_1, h_2, \ldots, h_n]$$

å…¶ä¸­ $h_i$ æ˜¯ç¬¬iä¸ªæ–¹å‘binçš„æ¢¯åº¦å¼ºåº¦ã€‚

### 2. åˆ†ç±»å™¨ç†è®º

#### 2.1 æ”¯æŒå‘é‡æœº

SVMçš„å†³ç­–å‡½æ•°ï¼š

$$f(x) = \text{sign}\left(\sum_{i=1}^{n} \alpha_i y_i K(x_i, x) + b\right)$$

å…¶ä¸­ $K(x_i, x)$ æ˜¯æ ¸å‡½æ•°ã€‚

#### 2.2 éšæœºæ£®æ—

éšæœºæ£®æ—çš„é¢„æµ‹ï¼š

$$\hat{y} = \frac{1}{T}\sum_{t=1}^{T} f_t(x)$$

å…¶ä¸­ $f_t(x)$ æ˜¯ç¬¬tæ£µæ ‘çš„é¢„æµ‹ã€‚

#### 2.3 ç¥ç»ç½‘ç»œ

ç¥ç»ç½‘ç»œçš„è¾“å‡ºï¼š

$$y = \sigma(W^T x + b)$$

å…¶ä¸­ $\sigma$ æ˜¯æ¿€æ´»å‡½æ•°ã€‚

### 3. æ·±åº¦å­¦ä¹ 

#### 3.1 å·ç§¯ç¥ç»ç½‘ç»œ

å·ç§¯å±‚çš„è¾“å‡ºï¼š

$$y_{i,j} = \sum_{k,l} w_{k,l} x_{i+k,j+l} + b$$

#### 3.2 åå‘ä¼ æ’­

æƒé‡æ›´æ–°è§„åˆ™ï¼š

$$\Delta w = -\eta \frac{\partial L}{\partial w}$$

å…¶ä¸­ $\eta$ æ˜¯å­¦ä¹ ç‡ï¼Œ$L$ æ˜¯æŸå¤±å‡½æ•°ã€‚

## ğŸ”§ Haskellå®ç°

### 1. å›¾åƒå¤„ç†åŸºç¡€

```haskell
{-# LANGUAGE DataKinds #-}
{-# LANGUAGE GADTs #-}
{-# LANGUAGE TypeFamilies #-}
{-# LANGUAGE FlexibleInstances #-}

module ComputerVision.PatternRecognition where

import Data.List
import Data.Maybe
import Control.Monad.State
import Data.Vector (Vector)
import qualified Data.Vector as V
import Data.Matrix (Matrix)
import qualified Data.Matrix as M

-- åƒç´ ç±»å‹
type Pixel = (Int, Int, Int)  -- RGB
type GrayPixel = Double

-- å›¾åƒç±»å‹
data Image = Image
  { width :: Int
  , height :: Int
  , pixels :: Matrix Pixel
  } deriving Show

-- ç°åº¦å›¾åƒ
data GrayImage = GrayImage
  { grayWidth :: Int
  , grayHeight :: Int
  , grayPixels :: Matrix GrayPixel
  } deriving Show

-- åˆ›å»ºå›¾åƒ
createImage :: Int -> Int -> Image
createImage w h = 
  let pixels = M.matrix h w (\(i, j) -> (0, 0, 0))
  in Image w h pixels

-- åˆ›å»ºç°åº¦å›¾åƒ
createGrayImage :: Int -> Int -> GrayImage
createGrayImage w h = 
  let pixels = M.matrix h w (\(i, j) -> 0.0)
  in GrayImage w h pixels

-- RGBè½¬ç°åº¦
rgbToGray :: Pixel -> GrayPixel
rgbToGray (r, g, b) = 0.299 * fromIntegral r + 0.587 * fromIntegral g + 0.114 * fromIntegral b

-- å›¾åƒè½¬ç°åº¦
imageToGray :: Image -> GrayImage
imageToGray (Image w h pixels) = 
  let grayPixels = M.mapPos (\(i, j) _ -> rgbToGray (M.getElem (i+1) (j+1) pixels)) pixels
  in GrayImage w h grayPixels
```

### 2. ç‰¹å¾æå–

```haskell
-- ç‰¹å¾ç±»å‹
data Feature = 
  EdgeFeature (Matrix Double)
  | SIFTFeature [Double]
  | HOGFeature [Double]
  | ColorFeature [Double]
  deriving Show

-- è¾¹ç¼˜æ£€æµ‹
detectEdges :: GrayImage -> Matrix Double
detectEdges (GrayImage w h pixels) = 
  let -- Sobelç®—å­
      sobelX = M.fromLists [[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]]
      sobelY = M.fromLists [[-1, -2, -1], [0, 0, 0], [1, 2, 1]]
      
      -- åº”ç”¨å·ç§¯
      gradX = convolve2D pixels sobelX
      gradY = convolve2D pixels sobelY
      
      -- è®¡ç®—æ¢¯åº¦å¹…å€¼
      gradientMagnitude = M.elementwise (\x y -> sqrt (x^2 + y^2)) gradX gradY
  in gradientMagnitude

-- 2Då·ç§¯
convolve2D :: Matrix Double -> Matrix Double -> Matrix Double
convolve2D image kernel = 
  let (imgRows, imgCols) = (M.nrows image, M.ncols image)
      (kerRows, kerCols) = (M.nrows kernel, M.ncols kernel)
      
      -- è¾¹ç•Œå¡«å……
      paddedImage = padImage image (kerRows `div` 2) (kerCols `div` 2)
      
      -- å·ç§¯è®¡ç®—
      result = M.matrix imgRows imgCols (\(i, j) -> 
                convolveAt paddedImage kernel (i+1) (j+1))
  in result

-- å›¾åƒå¡«å……
padImage :: Matrix Double -> Int -> Int -> Matrix Double
padImage image padRows padCols = 
  let (rows, cols) = (M.nrows image, M.ncols image)
      paddedRows = rows + 2 * padRows
      paddedCols = cols + 2 * padCols
      
      padded = M.matrix paddedRows paddedCols (\(i, j) -> 
                if i > padRows && i <= padRows + rows && 
                   j > padCols && j <= padCols + cols
                then M.getElem (i-padRows) (j-padCols) image
                else 0.0)
  in padded

-- åœ¨æŒ‡å®šä½ç½®å·ç§¯
convolveAt :: Matrix Double -> Matrix Double -> Int -> Int -> Double
convolveAt image kernel centerRow centerCol = 
  let (kerRows, kerCols) = (M.nrows kernel, M.ncols kernel)
      halfRows = kerRows `div` 2
      halfCols = kerCols `div` 2
      
      -- è®¡ç®—å·ç§¯å’Œ
      sum = foldl (+) 0.0 [M.getElem (centerRow + i - halfRows - 1) 
                                    (centerCol + j - halfCols - 1) image * 
                           M.getElem (i+1) (j+1) kernel
                          | i <- [0..kerRows-1], j <- [0..kerCols-1]]
  in sum

-- SIFTç‰¹å¾æå–
extractSIFTFeatures :: GrayImage -> [SIFTFeature]
extractSIFTFeatures (GrayImage w h pixels) = 
  let -- æ£€æµ‹å…³é”®ç‚¹
      keypoints = detectKeypoints pixels
      
      -- ä¸ºæ¯ä¸ªå…³é”®ç‚¹è®¡ç®—æè¿°å­
      descriptors = map (computeSIFTDescriptor pixels) keypoints
  in descriptors

-- å…³é”®ç‚¹æ£€æµ‹
detectKeypoints :: Matrix Double -> [(Int, Int)]
detectKeypoints pixels = 
  let (rows, cols) = (M.nrows pixels, M.ncols pixels)
      -- ç®€åŒ–ï¼šæ£€æµ‹å±€éƒ¨æœ€å¤§å€¼
      keypoints = [(i, j) | i <- [1..rows-2], j <- [1..cols-2],
                           isLocalMaximum pixels i j]
  in keypoints

-- å±€éƒ¨æœ€å¤§å€¼æ£€æµ‹
isLocalMaximum :: Matrix Double -> Int -> Int -> Bool
isLocalMaximum pixels i j = 
  let center = M.getElem i j pixels
      neighbors = [M.getElem (i+di) (j+dj) pixels 
                  | di <- [-1,0,1], dj <- [-1,0,1], di /= 0 || dj /= 0]
  in all (<= center) neighbors

-- è®¡ç®—SIFTæè¿°å­
computeSIFTDescriptor :: Matrix Double -> (Int, Int) -> SIFTFeature
computeSIFTDescriptor pixels (i, j) = 
  let -- æå–16x16çš„é‚»åŸŸ
      neighborhood = extractNeighborhood pixels i j 8
      
      -- è®¡ç®—æ¢¯åº¦
      gradients = computeGradients neighborhood
      
      -- æ„å»ºæ–¹å‘ç›´æ–¹å›¾
      histogram = buildGradientHistogram gradients
  in SIFTFeature histogram

-- æå–é‚»åŸŸ
extractNeighborhood :: Matrix Double -> Int -> Int -> Int -> Matrix Double
extractNeighborhood pixels centerI centerJ radius = 
  let size = 2 * radius + 1
      neighborhood = M.matrix size size (\(i, j) -> 
                      let imgI = centerI + i - radius - 1
                          imgJ = centerJ + j - radius - 1
                      in if imgI >= 1 && imgI <= M.nrows pixels && 
                            imgJ >= 1 && imgJ <= M.ncols pixels
                         then M.getElem imgI imgJ pixels
                         else 0.0)
  in neighborhood

-- è®¡ç®—æ¢¯åº¦
computeGradients :: Matrix Double -> (Matrix Double, Matrix Double)
computeGradients image = 
  let gradX = convolve2D image (M.fromLists [[-1, 0, 1]])
      gradY = convolve2D image (M.fromLists [[-1], [0], [1]])
  in (gradX, gradY)

-- æ„å»ºæ¢¯åº¦ç›´æ–¹å›¾
buildGradientHistogram :: (Matrix Double, Matrix Double) -> [Double]
buildGradientHistogram (gradX, gradY) = 
  let (rows, cols) = (M.nrows gradX, M.ncols gradX)
      numBins = 8
      
      -- è®¡ç®—æ‰€æœ‰åƒç´ çš„æ¢¯åº¦æ–¹å‘å’Œå¹…å€¼
      gradients = [(M.getElem i j gradX, M.getElem i j gradY) 
                   | i <- [1..rows], j <- [1..cols]]
      
      -- æ„å»ºç›´æ–¹å›¾
      histogram = replicate numBins 0.0
      updatedHistogram = foldl updateHistogram histogram gradients
  in updatedHistogram
  where updateHistogram hist (gx, gy) = 
          let magnitude = sqrt (gx^2 + gy^2)
              angle = atan2 gy gx
              bin = floor ((angle + pi) / (2 * pi) * fromIntegral (length hist)) `mod` length hist
          in take bin hist ++ [hist !! bin + magnitude] ++ drop (bin + 1) hist

-- HOGç‰¹å¾æå–
extractHOGFeatures :: GrayImage -> HOGFeature
extractHOGFeatures (GrayImage w h pixels) = 
  let -- å°†å›¾åƒåˆ†å‰²ä¸ºå•å…ƒæ ¼
      cellSize = 8
      numCellsX = w `div` cellSize
      numCellsY = h `div` cellSize
      
      -- ä¸ºæ¯ä¸ªå•å…ƒæ ¼è®¡ç®—HOG
      cellHOGs = [computeCellHOG pixels i j cellSize 
                  | i <- [0..numCellsY-1], j <- [0..numCellsX-1]]
      
      -- è¿æ¥æ‰€æœ‰å•å…ƒæ ¼çš„HOG
      hogFeatures = concat cellHOGs
  in HOGFeature hogFeatures

-- è®¡ç®—å•å…ƒæ ¼HOG
computeCellHOG :: Matrix Double -> Int -> Int -> Int -> [Double]
computeCellHOG pixels cellI cellJ cellSize = 
  let -- æå–å•å…ƒæ ¼
      startI = cellI * cellSize + 1
      startJ = cellJ * cellSize + 1
      endI = startI + cellSize - 1
      endJ = startJ + cellSize - 1
      
      cell = M.submatrix startI endI startJ endJ pixels
      
      -- è®¡ç®—æ¢¯åº¦
      (gradX, gradY) = computeGradients cell
      
      -- æ„å»ºæ–¹å‘ç›´æ–¹å›¾
      histogram = buildGradientHistogram (gradX, gradY)
  in histogram
```

### 3. åˆ†ç±»å™¨å®ç°

```haskell
-- åˆ†ç±»å™¨ç±»å‹
data Classifier = 
  SVMClassifier [Double] Double  -- æƒé‡å‘é‡å’Œåç½®
  | RandomForestClassifier [DecisionTree]  -- å†³ç­–æ ‘é›†åˆ
  | NeuralNetworkClassifier NeuralNetwork  -- ç¥ç»ç½‘ç»œ
  deriving Show

-- å†³ç­–æ ‘
data DecisionTree = 
  Leaf String  -- ç±»åˆ«æ ‡ç­¾
  | Node Int Double DecisionTree DecisionTree  -- ç‰¹å¾ç´¢å¼•ã€é˜ˆå€¼ã€å·¦å³å­æ ‘
  deriving Show

-- ç¥ç»ç½‘ç»œ
data NeuralNetwork = NeuralNetwork
  { layers :: [Layer]
  , weights :: [Matrix Double]
  , biases :: [Vector Double]
  } deriving Show

-- ç¥ç»ç½‘ç»œå±‚
data Layer = 
  InputLayer Int
  | HiddenLayer Int ActivationFunction
  | OutputLayer Int ActivationFunction
  deriving Show

-- æ¿€æ´»å‡½æ•°
data ActivationFunction = 
  Sigmoid
  | ReLU
  | Tanh
  deriving Show

-- SVMåˆ†ç±»å™¨
trainSVM :: [(Feature, String)] -> Classifier
trainSVM trainingData = 
  let -- ç®€åŒ–çš„SVMè®­ç»ƒ
      features = map fst trainingData
      labels = map snd trainingData
      
      -- ç‰¹å¾å‘é‡åŒ–
      featureVectors = map featureToVector features
      
      -- è®¡ç®—æƒé‡ï¼ˆç®€åŒ–ï¼šä½¿ç”¨çº¿æ€§ç»„åˆï¼‰
      weights = computeSVMWeights featureVectors labels
      bias = 0.0  -- ç®€åŒ–ï¼šå›ºå®šåç½®
  in SVMClassifier weights bias

-- ç‰¹å¾å‘é‡åŒ–
featureToVector :: Feature -> [Double]
featureToVector feature = case feature of
  EdgeFeature _ -> replicate 100 0.0  -- ç®€åŒ–ï¼šå›ºå®šç»´åº¦
  SIFTFeature desc -> desc
  HOGFeature hog -> hog
  ColorFeature color -> color

-- è®¡ç®—SVMæƒé‡
computeSVMWeights :: [[Double]] -> [String] -> [Double]
computeSVMWeights features labels = 
  let numFeatures = length (head features)
      -- ç®€åŒ–ï¼šéšæœºåˆå§‹åŒ–æƒé‡
      weights = [0.1 * fromIntegral (i `mod` 10) | i <- [0..numFeatures-1]]
  in weights

-- SVMé¢„æµ‹
predictSVM :: SVMClassifier -> Feature -> String
predictSVM (SVMClassifier weights bias) feature = 
  let featureVector = featureToVector feature
      score = sum (zipWith (*) weights featureVector) + bias
  in if score > 0 then "positive" else "negative"

-- éšæœºæ£®æ—è®­ç»ƒ
trainRandomForest :: [(Feature, String)] -> Int -> Classifier
trainRandomForest trainingData numTrees = 
  let -- è®­ç»ƒå¤šæ£µå†³ç­–æ ‘
      trees = [trainDecisionTree trainingData | _ <- [1..numTrees]]
  in RandomForestClassifier trees

-- å†³ç­–æ ‘è®­ç»ƒ
trainDecisionTree :: [(Feature, String)] -> DecisionTree
trainDecisionTree data = 
  let -- ç®€åŒ–çš„å†³ç­–æ ‘è®­ç»ƒ
      features = map fst data
      labels = map snd data
      
      -- æ£€æŸ¥æ˜¯å¦æ‰€æœ‰æ ‡ç­¾ç›¸åŒ
      uniqueLabels = nub labels
  in if length uniqueLabels == 1
     then Leaf (head uniqueLabels)
     else 
       let -- é€‰æ‹©æœ€ä½³åˆ†å‰²ç‰¹å¾
           bestSplit = findBestSplit features labels
       in case bestSplit of
            Just (featureIndex, threshold) -> 
              let (leftData, rightData) = splitData data featureIndex threshold
                  leftTree = trainDecisionTree leftData
                  rightTree = trainDecisionTree rightData
              in Node featureIndex threshold leftTree rightTree
            Nothing -> Leaf (mostCommonLabel labels)

-- æ‰¾åˆ°æœ€ä½³åˆ†å‰²
findBestSplit :: [Feature] -> [String] -> Maybe (Int, Double)
findBestSplit features labels = 
  let -- ç®€åŒ–ï¼šé€‰æ‹©ç¬¬ä¸€ä¸ªç‰¹å¾å’Œä¸­é—´å€¼ä½œä¸ºåˆ†å‰²
      featureVectors = map featureToVector features
      numFeatures = length (head featureVectors)
  in if numFeatures > 0
     then Just (0, 0.5)  -- ç®€åŒ–ï¼šå›ºå®šåˆ†å‰²
     else Nothing

-- åˆ†å‰²æ•°æ®
splitData :: [(Feature, String)] -> Int -> Double -> ([(Feature, String)], [(Feature, String)])
splitData data featureIndex threshold = 
  let splitFeature :: Feature -> Double
      splitFeature feature = 
        let vector = featureToVector feature
        in if featureIndex < length vector 
           then vector !! featureIndex 
           else 0.0
      
      (left, right) = partition (\(feature, _) -> splitFeature feature <= threshold) data
  in (left, right)

-- æœ€å¸¸è§æ ‡ç­¾
mostCommonLabel :: [String] -> String
mostCommonLabel labels = 
  let labelCounts = [(label, length (filter (== label) labels)) | label <- nub labels]
      (mostCommon, _) = maximumBy (\a b -> compare (snd a) (snd b)) labelCounts
  in mostCommon

-- éšæœºæ£®æ—é¢„æµ‹
predictRandomForest :: RandomForestClassifier -> Feature -> String
predictRandomForest (RandomForestClassifier trees) feature = 
  let -- æ¯æ£µæ ‘è¿›è¡Œé¢„æµ‹
      predictions = map (\tree -> predictDecisionTree tree feature) trees
      
      -- å¤šæ•°è¡¨å†³
      predictionCounts = [(label, length (filter (== label) predictions)) 
                          | label <- nub predictions]
      (finalPrediction, _) = maximumBy (\a b -> compare (snd a) (snd b)) predictionCounts
  in finalPrediction

-- å†³ç­–æ ‘é¢„æµ‹
predictDecisionTree :: DecisionTree -> Feature -> String
predictDecisionTree (Leaf label) _ = label
predictDecisionTree (Node featureIndex threshold leftTree rightTree) feature = 
  let featureVector = featureToVector feature
      featureValue = if featureIndex < length featureVector 
                     then featureVector !! featureIndex 
                     else 0.0
  in if featureValue <= threshold
     then predictDecisionTree leftTree feature
     else predictDecisionTree rightTree feature
```

### 4. æ·±åº¦å­¦ä¹ 

```haskell
-- å·ç§¯ç¥ç»ç½‘ç»œ
data CNN = CNN
  { convLayers :: [ConvLayer]
  , poolingLayers :: [PoolingLayer]
  , fullyConnectedLayers :: [FCLayer]
  } deriving Show

-- å·ç§¯å±‚
data ConvLayer = ConvLayer
  { filters :: [Matrix Double]
  , bias :: Double
  , activation :: ActivationFunction
  } deriving Show

-- æ± åŒ–å±‚
data PoolingLayer = PoolingLayer
  { poolSize :: Int
  , poolType :: PoolingType
  } deriving Show

-- æ± åŒ–ç±»å‹
data PoolingType = 
  MaxPooling
  | AveragePooling
  deriving Show

-- å…¨è¿æ¥å±‚
data FCLayer = FCLayer
  { weights :: Matrix Double
  , bias :: Vector Double
  , activation :: ActivationFunction
  } deriving Show

-- åˆ›å»ºCNN
createCNN :: CNN
createCNN = 
  let -- å·ç§¯å±‚
      conv1 = ConvLayer 
        { filters = [createRandomFilter 3 3, createRandomFilter 3 3]
        , bias = 0.0
        , activation = ReLU
        }
      
      -- æ± åŒ–å±‚
      pool1 = PoolingLayer 
        { poolSize = 2
        , poolType = MaxPooling
        }
      
      -- å…¨è¿æ¥å±‚
      fc1 = FCLayer
        { weights = M.matrix 128 64 (\(i, j) -> 0.1)
        , bias = V.replicate 128 0.0
        , activation = ReLU
        }
      
      fc2 = FCLayer
        { weights = M.matrix 10 128 (\(i, j) -> 0.1)
        , bias = V.replicate 10 0.0
        , activation = Sigmoid
        }
  in CNN [conv1] [pool1] [fc1, fc2]

-- åˆ›å»ºéšæœºæ»¤æ³¢å™¨
createRandomFilter :: Int -> Int -> Matrix Double
createRandomFilter rows cols = 
  M.matrix rows cols (\(i, j) -> 0.1 * fromIntegral ((i + j) `mod` 5))

-- CNNå‰å‘ä¼ æ’­
forwardPass :: CNN -> GrayImage -> [Double]
forwardPass cnn (GrayImage w h pixels) = 
  let -- å·ç§¯å±‚
      convOutput = foldl applyConvLayer pixels (convLayers cnn)
      
      -- æ± åŒ–å±‚
      pooledOutput = foldl applyPoolingLayer convOutput (poolingLayers cnn)
      
      -- å…¨è¿æ¥å±‚
      flattened = flattenMatrix pooledOutput
      fcOutput = foldl applyFCLayer flattened (fullyConnectedLayers cnn)
  in fcOutput

-- åº”ç”¨å·ç§¯å±‚
applyConvLayer :: Matrix Double -> ConvLayer -> Matrix Double
applyConvLayer input (ConvLayer filters bias activation) = 
  let -- åº”ç”¨æ‰€æœ‰æ»¤æ³¢å™¨
      convResults = map (\filter -> convolve2D input filter) filters
      
      -- æ±‚å’Œå¹¶æ·»åŠ åç½®
      summed = foldl (M.elementwise (+)) (head convResults) (tail convResults)
      withBias = M.map (+ bias) summed
      
      -- åº”ç”¨æ¿€æ´»å‡½æ•°
      activated = M.map (applyActivation activation) withBias
  in activated

-- åº”ç”¨æ± åŒ–å±‚
applyPoolingLayer :: Matrix Double -> PoolingLayer -> Matrix Double
applyPoolingLayer input (PoolingLayer size poolType) = 
  let (rows, cols) = (M.nrows input, M.ncols input)
      outputRows = rows `div` size
      outputCols = cols `div` size
      
      pooled = M.matrix outputRows outputCols (\(i, j) -> 
                let startRow = i * size + 1
                    startCol = j * size + 1
                    endRow = min (startRow + size - 1) rows
                    endCol = min (startCol + size - 1) cols
                    
                    window = M.submatrix startRow endRow startCol endCol input
                    values = [M.getElem r c window | r <- [1..M.nrows window], c <- [1..M.ncols window]]
                in case poolType of
                     MaxPooling -> maximum values
                     AveragePooling -> sum values / fromIntegral (length values))
  in pooled

-- åº”ç”¨å…¨è¿æ¥å±‚
applyFCLayer :: [Double] -> FCLayer -> [Double]
applyFCLayer input (FCLayer weights bias activation) = 
  let -- çŸ©é˜µä¹˜æ³•
      output = M.multStd (M.fromLists [input]) weights
      outputList = M.toLists output !! 0
      
      -- æ·»åŠ åç½®
      withBias = zipWith (+) outputList (V.toList bias)
      
      -- åº”ç”¨æ¿€æ´»å‡½æ•°
      activated = map (applyActivation activation) withBias
  in activated

-- åº”ç”¨æ¿€æ´»å‡½æ•°
applyActivation :: ActivationFunction -> Double -> Double
applyActivation activation x = case activation of
  Sigmoid -> 1.0 / (1.0 + exp (-x))
  ReLU -> max 0.0 x
  Tanh -> tanh x

-- å±•å¹³çŸ©é˜µ
flattenMatrix :: Matrix Double -> [Double]
flattenMatrix matrix = 
  [M.getElem i j matrix | i <- [1..M.nrows matrix], j <- [1..M.ncols matrix]]
```

### 5. æ¨¡å¼è¯†åˆ«ç³»ç»Ÿ

```haskell
-- æ¨¡å¼è¯†åˆ«ç³»ç»Ÿ
data PatternRecognitionSystem = PatternRecognitionSystem
  { featureExtractor :: GrayImage -> [Feature]
  , classifier :: Classifier
  , preprocessor :: GrayImage -> GrayImage
  } deriving Show

-- è®­ç»ƒæ¨¡å¼è¯†åˆ«ç³»ç»Ÿ
trainPatternRecognitionSystem :: [(GrayImage, String)] -> PatternRecognitionSystem
trainPatternRecognitionSystem trainingData = 
  let -- é¢„å¤„ç†å›¾åƒ
      preprocessedImages = map (\(image, label) -> (preprocessImage image, label)) trainingData
      
      -- æå–ç‰¹å¾
      featuresWithLabels = map (\(image, label) -> (extractFeatures image, label)) preprocessedImages
      
      -- è®­ç»ƒåˆ†ç±»å™¨
      trainedClassifier = trainSVM featuresWithLabels
      
      -- æ„å»ºç³»ç»Ÿ
      system = PatternRecognitionSystem
        { featureExtractor = extractFeatures
        , classifier = trainedClassifier
        , preprocessor = preprocessImage
        }
  in system

-- é¢„å¤„ç†å›¾åƒ
preprocessImage :: GrayImage -> GrayImage
preprocessImage image = 
  let -- å½’ä¸€åŒ–
      normalized = normalizeImage image
      
      -- é«˜æ–¯æ»¤æ³¢
      filtered = applyGaussianFilter normalized
  in filtered

-- å›¾åƒå½’ä¸€åŒ–
normalizeImage :: GrayImage -> GrayImage
normalizeImage (GrayImage w h pixels) = 
  let maxVal = M.maxElement pixels
      minVal = M.minElement pixels
      range = maxVal - minVal
      
      normalized = if range > 0
                   then M.map (\p -> (p - minVal) / range) pixels
                   else pixels
  in GrayImage w h normalized

-- åº”ç”¨é«˜æ–¯æ»¤æ³¢
applyGaussianFilter :: GrayImage -> GrayImage
applyGaussianFilter (GrayImage w h pixels) = 
  let -- 3x3é«˜æ–¯æ ¸
      gaussianKernel = M.fromLists 
        [[1/16, 1/8, 1/16],
         [1/8,  1/4, 1/8],
         [1/16, 1/8, 1/16]]
      
      filtered = convolve2D pixels gaussianKernel
  in GrayImage w h filtered

-- æå–ç‰¹å¾
extractFeatures :: GrayImage -> [Feature]
extractFeatures image = 
  let -- è¾¹ç¼˜ç‰¹å¾
      edgeFeature = EdgeFeature (detectEdges image)
      
      -- SIFTç‰¹å¾
      siftFeatures = extractSIFTFeatures image
      
      -- HOGç‰¹å¾
      hogFeature = extractHOGFeatures image
  in edgeFeature : siftFeatures ++ [hogFeature]

-- æ¨¡å¼è¯†åˆ«
recognizePattern :: PatternRecognitionSystem -> GrayImage -> String
recognizePattern system image = 
  let -- é¢„å¤„ç†
      preprocessed = preprocessor system image
      
      -- ç‰¹å¾æå–
      features = featureExtractor system preprocessed
      
      -- åˆ†ç±»
      predictions = map (\feature -> classifyFeature (classifier system) feature) features
      
      -- å¤šæ•°è¡¨å†³
      finalPrediction = mostCommonLabel predictions
  in finalPrediction

-- åˆ†ç±»ç‰¹å¾
classifyFeature :: Classifier -> Feature -> String
classifyFeature classifier feature = case classifier of
  SVMClassifier weights bias -> predictSVM (SVMClassifier weights bias) feature
  RandomForestClassifier trees -> predictRandomForest (RandomForestClassifier trees) feature
  NeuralNetworkClassifier _ -> "unknown"  -- ç®€åŒ–
```

## ğŸ“Š åº”ç”¨å®ä¾‹

### 1. äººè„¸è¯†åˆ«ç³»ç»Ÿ

```haskell
-- äººè„¸è¯†åˆ«
faceRecognitionSystem :: PatternRecognitionSystem
faceRecognitionSystem = PatternRecognitionSystem
  { featureExtractor = extractFaceFeatures
  , classifier = SVMClassifier [0.1, 0.2, 0.3] 0.0
  , preprocessor = preprocessFaceImage
  }

-- äººè„¸ç‰¹å¾æå–
extractFaceFeatures :: GrayImage -> [Feature]
extractFaceFeatures image = 
  let -- æ£€æµ‹é¢éƒ¨å…³é”®ç‚¹
      keypoints = detectFaceKeypoints image
      
      -- æå–å±€éƒ¨ç‰¹å¾
      localFeatures = map (extractLocalFeature image) keypoints
      
      -- å…¨å±€ç‰¹å¾
      globalFeatures = [extractHOGFeatures image]
  in localFeatures ++ globalFeatures

-- æ£€æµ‹é¢éƒ¨å…³é”®ç‚¹
detectFaceKeypoints :: GrayImage -> [(Int, Int)]
detectFaceKeypoints image = 
  -- ç®€åŒ–ï¼šå›ºå®šå…³é”®ç‚¹ä½ç½®
  [(100, 100), (150, 100), (200, 100), (125, 150), (175, 150)]

-- æå–å±€éƒ¨ç‰¹å¾
extractLocalFeature :: GrayImage -> (Int, Int) -> Feature
extractLocalFeature image (x, y) = 
  let -- æå–å±€éƒ¨é‚»åŸŸ
      neighborhood = extractNeighborhood (grayPixels image) x y 16
      
      -- è®¡ç®—SIFTç‰¹å¾
      siftFeature = computeSIFTDescriptor neighborhood (8, 8)
  in siftFeature

-- é¢„å¤„ç†äººè„¸å›¾åƒ
preprocessFaceImage :: GrayImage -> GrayImage
preprocessFaceImage image = 
  let -- ç›´æ–¹å›¾å‡è¡¡åŒ–
      equalized = histogramEqualization image
      
      -- å°ºå¯¸æ ‡å‡†åŒ–
      resized = resizeImage equalized 128 128
  in resized

-- ç›´æ–¹å›¾å‡è¡¡åŒ–
histogramEqualization :: GrayImage -> GrayImage
histogramEqualization (GrayImage w h pixels) = 
  let -- è®¡ç®—ç›´æ–¹å›¾
      histogram = computeHistogram pixels
      
      -- è®¡ç®—ç´¯ç§¯åˆ†å¸ƒ
      cdf = computeCDF histogram
      
      -- åº”ç”¨å‡è¡¡åŒ–
      equalized = M.map (\p -> cdf !! floor (p * 255)) pixels
  in GrayImage w h equalized

-- è®¡ç®—ç›´æ–¹å›¾
computeHistogram :: Matrix Double -> [Int]
computeHistogram pixels = 
  let values = [floor (M.getElem i j pixels * 255) | i <- [1..M.nrows pixels], j <- [1..M.ncols pixels]]
  in [length (filter (== i) values) | i <- [0..255]]

-- è®¡ç®—ç´¯ç§¯åˆ†å¸ƒ
computeCDF :: [Int] -> [Double]
computeCDF histogram = 
  let total = sum histogram
      cumulative = scanl (+) 0 histogram
  in map (\c -> fromIntegral c / fromIntegral total) cumulative

-- è°ƒæ•´å›¾åƒå°ºå¯¸
resizeImage :: GrayImage -> Int -> Int -> GrayImage
resizeImage (GrayImage w h pixels) newW newH = 
  let -- ç®€åŒ–çš„åŒçº¿æ€§æ’å€¼
      resized = M.matrix newH newW (\(i, j) -> 
                 let oldI = fromIntegral i * fromIntegral h / fromIntegral newH
                     oldJ = fromIntegral j * fromIntegral w / fromIntegral newW
                     
                     i1 = floor oldI
                     j1 = floor oldJ
                     
                     -- è¾¹ç•Œæ£€æŸ¥
                     safeI = max 1 (min i1 (M.nrows pixels))
                     safeJ = max 1 (min j1 (M.ncols pixels))
                 in M.getElem safeI safeJ pixels)
  in GrayImage newW newH resized
```

### 2. ç‰©ä½“æ£€æµ‹ç³»ç»Ÿ

```haskell
-- ç‰©ä½“æ£€æµ‹
objectDetectionSystem :: PatternRecognitionSystem
objectDetectionSystem = PatternRecognitionSystem
  { featureExtractor = extractObjectFeatures
  , classifier = RandomForestClassifier []
  , preprocessor = preprocessObjectImage
  }

-- ç‰©ä½“ç‰¹å¾æå–
extractObjectFeatures :: GrayImage -> [Feature]
extractObjectFeatures image = 
  let -- å¤šå°ºåº¦ç‰¹å¾
      scales = [0.5, 1.0, 2.0]
      multiScaleFeatures = concatMap (\scale -> extractScaleFeatures image scale) scales
      
      -- é¢œè‰²ç‰¹å¾
      colorFeatures = extractColorFeatures image
  in multiScaleFeatures ++ colorFeatures

-- æå–å°ºåº¦ç‰¹å¾
extractScaleFeatures :: GrayImage -> Double -> [Feature]
extractScaleFeatures image scale = 
  let -- ç¼©æ”¾å›¾åƒ
      scaledImage = scaleImage image scale
      
      -- æå–HOGç‰¹å¾
      hogFeature = extractHOGFeatures scaledImage
  in [hogFeature]

-- ç¼©æ”¾å›¾åƒ
scaleImage :: GrayImage -> Double -> GrayImage
scaleImage (GrayImage w h pixels) scale = 
  let newW = floor (fromIntegral w * scale)
      newH = floor (fromIntegral h * scale)
  in resizeImage (GrayImage w h pixels) newW newH

-- æå–é¢œè‰²ç‰¹å¾
extractColorFeatures :: GrayImage -> [Feature]
extractColorFeatures image = 
  let -- ç®€åŒ–çš„é¢œè‰²ç‰¹å¾
      colorHistogram = [0.1, 0.2, 0.3, 0.4]  -- å›ºå®šé¢œè‰²ç›´æ–¹å›¾
  in [ColorFeature colorHistogram]

-- é¢„å¤„ç†ç‰©ä½“å›¾åƒ
preprocessObjectImage :: GrayImage -> GrayImage
preprocessObjectImage image = 
  let -- å¯¹æ¯”åº¦å¢å¼º
      enhanced = enhanceContrast image
      
      -- å™ªå£°å»é™¤
      denoised = removeNoise enhanced
  in denoised

-- å¯¹æ¯”åº¦å¢å¼º
enhanceContrast :: GrayImage -> GrayImage
enhanceContrast (GrayImage w h pixels) = 
  let -- çº¿æ€§æ‹‰ä¼¸
      minVal = M.minElement pixels
      maxVal = M.maxElement pixels
      range = maxVal - minVal
      
      enhanced = if range > 0
                 then M.map (\p -> (p - minVal) / range) pixels
                 else pixels
  in GrayImage w h enhanced

-- å™ªå£°å»é™¤
removeNoise :: GrayImage -> GrayImage
removeNoise image = 
  let -- ä¸­å€¼æ»¤æ³¢
      filtered = applyMedianFilter image
  in filtered

-- åº”ç”¨ä¸­å€¼æ»¤æ³¢
applyMedianFilter :: GrayImage -> GrayImage
applyMedianFilter (GrayImage w h pixels) = 
  let -- 3x3ä¸­å€¼æ»¤æ³¢
      filtered = M.matrix h w (\(i, j) -> 
                  let window = extractWindow pixels i j 1
                      sorted = sort window
                      median = sorted !! (length sorted `div` 2)
                  in median)
  in GrayImage w h filtered

-- æå–çª—å£
extractWindow :: Matrix Double -> Int -> Int -> Int -> [Double]
extractWindow pixels centerI centerJ radius = 
  let (rows, cols) = (M.nrows pixels, M.ncols pixels)
      window = [M.getElem i j pixels 
                | i <- [max 1 (centerI - radius)..min rows (centerI + radius)]
                , j <- [max 1 (centerJ - radius)..min cols (centerJ + radius)]]
  in window
```

## ğŸ”— ç›¸å…³ç†è®º

- [å›¾åƒå¤„ç†åŸºç¡€](../13-Computer-Vision/01-Image-Processing.md)
- [æœºå™¨å­¦ä¹ ç†è®º](../14-Machine-Learning/01-Supervised-Learning.md)
- [æ·±åº¦å­¦ä¹ ç†è®º](../14-Machine-Learning/03-Deep-Learning.md)
- [ç»Ÿè®¡å­¦ä¹ ç†è®º](../14-Machine-Learning/02-Statistical-Learning.md)
- [ä¼˜åŒ–ç†è®º](../10-Mathematical-Physics/03-Optimization-Theory.md)

## ğŸ“š å‚è€ƒæ–‡çŒ®

1. Bishop, C. M. (2006). *Pattern Recognition and Machine Learning*. Springer.
2. Duda, R. O., Hart, P. E., & Stork, D. G. (2001). *Pattern Classification*. Wiley.
3. LeCun, Y., Bengio, Y., & Hinton, G. (2015). *Deep learning*. Nature.

---

**æ–‡æ¡£ç‰ˆæœ¬**: 1.0.0  
**ç»´æŠ¤è€…**: AI Assistant  
**æœ€åæ›´æ–°**: 2024å¹´12æœˆ19æ—¥ 